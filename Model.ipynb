{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6618adf7-185b-4be7-b511-ac8969c37529",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# dummy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f5586e6-8e80-4953-8a27-050ff2e31304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données...\n",
      "Données chargées avec succès.\n",
      "\n",
      "Préparation des données...\n",
      "Distribution des classes dans la cible :\n",
      "TARGET\n",
      "0    0.919271\n",
      "1    0.080729\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "\n",
      "Division des données en ensemble d'entraînement et de test...\n",
      "Division effectuée avec succès.\n",
      "\n",
      "Entraînement du DummyClassifier...\n",
      "Évaluation du modèle...\n",
      "Score d'entraînement du DummyClassifier: 0.919205879483594\n",
      "Score de test du DummyClassifier: 0.9195323805342829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1. Charger les données\n",
    "print(\"Chargement des données...\")\n",
    "df = pd.read_csv('data/application_train.csv')\n",
    "print(\"Données chargées avec succès.\\n\")\n",
    "\n",
    "# 2. Préparer les données (utiliser toutes les colonnes comme caractéristiques)\n",
    "print(\"Préparation des données...\")\n",
    "X = df.drop(columns=['TARGET'])\n",
    "y = df['TARGET']\n",
    "\n",
    "# Remplacer les valeurs manquantes pour les colonnes numériques\n",
    "X = X.fillna(X.median(numeric_only=True))  # Utiliser median pour les colonnes numériques\n",
    "\n",
    "# Identifier les colonnes numériques et catégorielles\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Prétraitement des caractéristiques\n",
    "numeric_transformer = SimpleImputer(strategy='median')\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Créer un pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DummyClassifier(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "# 3. Vérifier la distribution des classes\n",
    "print(\"Distribution des classes dans la cible :\")\n",
    "print(y.value_counts(normalize=True))\n",
    "print(\"\\n\")\n",
    "\n",
    "# 4. Diviser les données en ensemble d'entraînement et de test\n",
    "print(\"Division des données en ensemble d'entraînement et de test...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Division effectuée avec succès.\\n\")\n",
    "\n",
    "# 5. Entraîner et évaluer le DummyClassifier\n",
    "print(\"Entraînement du DummyClassifier...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 6. Évaluation du modèle\n",
    "print(\"Évaluation du modèle...\")\n",
    "train_score = pipeline.score(X_train, y_train)\n",
    "test_score = pipeline.score(X_test, y_test)\n",
    "print(f\"Score d'entraînement du DummyClassifier: {train_score}\")\n",
    "print(f\"Score de test du DummyClassifier: {test_score}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a20bab-1289-4310-898c-8d2cea2fe7ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f82790d-393e-4cfe-b9e1-4344ca280a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données...\n",
      "Données chargées avec succès.\n",
      "\n",
      "Préparation des données...\n",
      "Division des données en ensemble d'entraînement et de test...\n",
      "Division effectuée avec succès.\n",
      "\n",
      "Entraînement du modèle de régression logistique...\n",
      "Évaluation du modèle...\n",
      "Score d'entraînement du modèle de régression logistique: 0.919737801790418\n",
      "Score de test du modèle de régression logistique: 0.9181390508812626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1. Charger les données\n",
    "print(\"Chargement des données...\")\n",
    "df = pd.read_csv('data/application_train.csv')\n",
    "print(\"Données chargées avec succès.\\n\")\n",
    "\n",
    "# 2. Préparer les données (utiliser toutes les colonnes comme caractéristiques)\n",
    "print(\"Préparation des données...\")\n",
    "X = df.drop(columns=['TARGET'])\n",
    "y = df['TARGET']\n",
    "\n",
    "# Remplacer les valeurs manquantes pour les colonnes numériques\n",
    "X = X.fillna(X.median(numeric_only=True))  # Utiliser median pour les colonnes numériques\n",
    "\n",
    "# Identifier les colonnes numériques et catégorielles\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Prétraitement des caractéristiques\n",
    "numeric_transformer = SimpleImputer(strategy='median')\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Créer un pipeline avec LogisticRegression\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(solver='liblinear'))\n",
    "])\n",
    "\n",
    "# 3. Diviser les données en ensemble d'entraînement et de test\n",
    "print(\"Division des données en ensemble d'entraînement et de test...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(\"Division effectuée avec succès.\\n\")\n",
    "\n",
    "# 4. Entraîner le modèle de régression logistique\n",
    "print(\"Entraînement du modèle de régression logistique...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 5. Évaluation du modèle\n",
    "print(\"Évaluation du modèle...\")\n",
    "train_score = pipeline.score(X_train, y_train)\n",
    "test_score = pipeline.score(X_test, y_test)\n",
    "\n",
    "print(f\"Score d'entraînement du modèle de régression logistique: {train_score}\")\n",
    "print(f\"Score de test du modèle de régression logistique: {test_score}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaaee34-537b-48e1-a58f-39d31d4a0dcd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Arbre de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b84ed9f5-c62f-4f07-81fb-f221b34671ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données...\n",
      "Données chargées avec succès.\n",
      "\n",
      "Préparation des données...\n",
      "Distribution des classes dans la cible :\n",
      "TARGET\n",
      "0    0.919271\n",
      "1    0.080729\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "\n",
      "Division des données en ensemble d'entraînement et de test...\n",
      "Division effectuée avec succès.\n",
      "\n",
      "Entraînement du DecisionTreeClassifier...\n",
      "Évaluation du modèle...\n",
      "Score d'entraînement du DecisionTreeClassifier: 1.0\n",
      "Score de test du DecisionTreeClassifier: 0.8546296095562252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1. Charger les données\n",
    "print(\"Chargement des données...\")\n",
    "df = pd.read_csv('data/application_train.csv')\n",
    "print(\"Données chargées avec succès.\\n\")\n",
    "\n",
    "# 2. Préparer les données (utiliser toutes les colonnes comme caractéristiques)\n",
    "print(\"Préparation des données...\")\n",
    "X = df.drop(columns=['TARGET'])\n",
    "y = df['TARGET']\n",
    "\n",
    "# Remplacer les valeurs manquantes pour les colonnes numériques\n",
    "X = X.fillna(X.median(numeric_only=True))  # Utiliser median pour les colonnes numériques\n",
    "\n",
    "# Identifier les colonnes numériques et catégorielles\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Prétraitement des caractéristiques\n",
    "numeric_transformer = SimpleImputer(strategy='median')\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Créer un pipeline avec DecisionTreeClassifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "# 3. Vérifier la distribution des classes\n",
    "print(\"Distribution des classes dans la cible :\")\n",
    "print(y.value_counts(normalize=True))\n",
    "print(\"\\n\")\n",
    "\n",
    "# 4. Diviser les données en ensemble d'entraînement et de test\n",
    "print(\"Division des données en ensemble d'entraînement et de test...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(\"Division effectuée avec succès.\\n\")\n",
    "\n",
    "# 5. Entraîner et évaluer le DecisionTreeClassifier\n",
    "print(\"Entraînement du DecisionTreeClassifier...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 6. Évaluation du modèle\n",
    "print(\"Évaluation du modèle...\")\n",
    "train_score = pipeline.score(X_train, y_train)\n",
    "test_score = pipeline.score(X_test, y_test)\n",
    "print(f\"Score d'entraînement du DecisionTreeClassifier: {train_score}\")\n",
    "print(f\"Score de test du DecisionTreeClassifier: {test_score}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba041e5-589e-47e2-b0ef-1ab70bd3e15a",
   "metadata": {},
   "source": [
    "# random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "96529c7b-32f1-4220-8a95-c4da7e7140c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données...\n",
      "Données chargées avec succès.\n",
      "\n",
      "Préparation des données...\n",
      "Division des données en ensemble d'entraînement et de test...\n",
      "Division effectuée avec succès.\n",
      "\n",
      "Entraînement du modèle Random Forest...\n",
      "Évaluation du modèle...\n",
      "Score d'entraînement du modèle Random Forest: 0.9999581895130008\n",
      "Score de test du modèle Random Forest: 0.9193314111041255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1. Charger les données\n",
    "print(\"Chargement des données...\")\n",
    "df = pd.read_csv('data/application_train.csv')\n",
    "print(\"Données chargées avec succès.\\n\")\n",
    "\n",
    "# 2. Préparer les données (utiliser toutes les colonnes comme caractéristiques)\n",
    "print(\"Préparation des données...\")\n",
    "X = df.drop(columns=['TARGET'])\n",
    "y = df['TARGET']\n",
    "\n",
    "# Remplacer les valeurs manquantes pour les colonnes numériques\n",
    "X = X.fillna(X.median(numeric_only=True))  # Utiliser median pour les colonnes numériques\n",
    "\n",
    "# Identifier les colonnes numériques et catégorielles\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Prétraitement des caractéristiques\n",
    "numeric_transformer = SimpleImputer(strategy='median')\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Créer un pipeline avec RandomForestClassifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# 3. Diviser les données en ensemble d'entraînement et de test\n",
    "print(\"Division des données en ensemble d'entraînement et de test...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(\"Division effectuée avec succès.\\n\")\n",
    "\n",
    "# 4. Entraîner le modèle Random Forest\n",
    "print(\"Entraînement du modèle Random Forest...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 5. Évaluation du modèle\n",
    "print(\"Évaluation du modèle...\")\n",
    "train_score = pipeline.score(X_train, y_train)\n",
    "test_score = pipeline.score(X_test, y_test)\n",
    "\n",
    "print(f\"Score d'entraînement du modèle Random Forest: {train_score}\")\n",
    "print(f\"Score de test du modèle Random Forest: {test_score}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3809ee99-aa3f-4b84-b38d-ad14b59d6c8b",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9687199-5e9a-4ded-8caf-827f738d1b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données...\n",
      "Données chargées avec succès.\n",
      "\n",
      "Préparation des données...\n",
      "Division des données en ensemble d'entraînement et de test...\n",
      "Division effectuée avec succès.\n",
      "\n",
      "Entraînement du modèle LightGBM...\n",
      "[LightGBM] [Info] Number of positive: 17467, number of negative: 197790\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11684\n",
      "[LightGBM] [Info] Number of data points in the train set: 215257, number of used features: 240\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081145 -> initscore=-2.426892\n",
      "[LightGBM] [Info] Start training from score -2.426892\n",
      "Évaluation du modèle...\n",
      "Score d'entraînement du modèle LightGBM: 0.9200722856864121\n",
      "Score de test du modèle LightGBM: 0.9203069785591953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 1. Charger les données\n",
    "print(\"Chargement des données...\")\n",
    "df = pd.read_csv('data/application_train.csv')\n",
    "print(\"Données chargées avec succès.\\n\")\n",
    "\n",
    "# 2. Préparer les données (utiliser toutes les colonnes comme caractéristiques)\n",
    "print(\"Préparation des données...\")\n",
    "X = df.drop(columns=['TARGET'])\n",
    "y = df['TARGET']\n",
    "\n",
    "\n",
    "# Identifier les colonnes numériques et catégorielles\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Prétraitement des caractéristiques\n",
    "numeric_transformer = SimpleImputer(strategy='median')\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Créer un pipeline avec LGBMClassifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LGBMClassifier())\n",
    "])\n",
    "\n",
    "# 3. Diviser les données en ensemble d'entraînement et de test\n",
    "print(\"Division des données en ensemble d'entraînement et de test...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(\"Division effectuée avec succès.\\n\")\n",
    "\n",
    "# 4. Entraîner le modèle LightGBM\n",
    "print(\"Entraînement du modèle LightGBM...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 5. Évaluation du modèle\n",
    "print(\"Évaluation du modèle...\")\n",
    "train_score = pipeline.score(X_train, y_train)\n",
    "test_score = pipeline.score(X_test, y_test)\n",
    "\n",
    "print(f\"Score d'entraînement du modèle LightGBM: {train_score}\")\n",
    "print(f\"Score de test du modèle LightGBM: {test_score}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a44ff8-8cb4-499e-9f19-764e4e2fc515",
   "metadata": {},
   "source": [
    "# catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "888c1b15-6d1d-4d48-8aab-245cfd2914db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données...\n",
      "Données chargées avec succès.\n",
      "\n",
      "Préparation des données...\n",
      "Division des données en ensemble d'entraînement et de test...\n",
      "Division effectuée avec succès.\n",
      "\n",
      "Entraînement du modèle CatBoost...\n",
      "0:\tlearn: 0.5902242\ttotal: 135ms\tremaining: 1m 7s\n",
      "100:\tlearn: 0.2452817\ttotal: 5.71s\tremaining: 22.6s\n",
      "200:\tlearn: 0.2410434\ttotal: 11.3s\tremaining: 16.8s\n",
      "300:\tlearn: 0.2379069\ttotal: 17s\tremaining: 11.3s\n",
      "400:\tlearn: 0.2352668\ttotal: 22.8s\tremaining: 5.62s\n",
      "499:\tlearn: 0.2329040\ttotal: 28.5s\tremaining: 0us\n",
      "Évaluation du modèle...\n",
      "Score d'entraînement du modèle CatBoost: 0.9219822119605866\n",
      "Score de test du modèle CatBoost: 0.919662455489976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 1. Charger les données\n",
    "print(\"Chargement des données...\")\n",
    "df = pd.read_csv('data/application_train.csv')\n",
    "print(\"Données chargées avec succès.\\n\")\n",
    "\n",
    "# 2. Préparer les données (utiliser toutes les colonnes comme caractéristiques)\n",
    "print(\"Préparation des données...\")\n",
    "X = df.drop(columns=['TARGET'])\n",
    "y = df['TARGET']\n",
    "\n",
    "# Identifier les colonnes catégorielles\n",
    "categorical_features_indices = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remplacer les valeurs manquantes dans les colonnes numériques et catégorielles\n",
    "X[categorical_features_indices] = X[categorical_features_indices].fillna('missing')  # Remplacer NaN par 'missing'\n",
    "X = X.fillna(X.median(numeric_only=True))  # Remplacer les valeurs manquantes dans les colonnes numériques par la médiane\n",
    "\n",
    "# 3. Diviser les données en ensemble d'entraînement et de test\n",
    "print(\"Division des données en ensemble d'entraînement et de test...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Division effectuée avec succès.\\n\")\n",
    "\n",
    "# 4. Entraîner le modèle CatBoost\n",
    "print(\"Entraînement du modèle CatBoost...\")\n",
    "model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    cat_features=categorical_features_indices,  # Passer la liste des colonnes catégorielles\n",
    "    verbose=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Évaluation du modèle\n",
    "print(\"Évaluation du modèle...\")\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Score d'entraînement du modèle CatBoost: {train_score}\")\n",
    "print(f\"Score de test du modèle CatBoost: {test_score}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187ef02b-738d-4749-a16a-7497d15baee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
