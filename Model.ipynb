{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d31b987a-dff1-476c-b26c-a57e68cacee1",
   "metadata": {},
   "source": [
    "# Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6d85fae-0e56-4a49-9bf7-ddd4681c4efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score du modèle sur les données d'entraînement : 0.8524786650376062\n",
      "   SK_ID_CURR  TARGET\n",
      "0      342180       0\n",
      "1      259636       0\n",
      "2      305882       0\n",
      "3      243264       0\n",
      "4      264946       0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Lire les données\n",
    "app_train = pd.read_csv('data/application_train_split.csv')\n",
    "app_test = pd.read_csv('data/application_test_split.csv')\n",
    "\n",
    "# Séparer les données d'entraînement\n",
    "if 'TARGET' in app_train:\n",
    "    train = app_train.drop(columns=['TARGET'])\n",
    "    train_labels = app_train['TARGET']\n",
    "else:\n",
    "    raise ValueError(\"La colonne 'TARGET' n'existe pas dans les données d'entraînement.\")\n",
    "\n",
    "# Préparer les colonnes numériques\n",
    "numeric_cols = train.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Imputer les valeurs manquantes pour les colonnes numériques\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "train_numeric = imputer.fit_transform(train[numeric_cols])\n",
    "test_numeric = imputer.transform(app_test[numeric_cols])\n",
    "\n",
    "# Normaliser les colonnes numériques\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_numeric = scaler.fit_transform(train_numeric)\n",
    "test_numeric = scaler.transform(test_numeric)\n",
    "\n",
    "# Créer et entraîner le DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "dummy_clf.fit(train_numeric, train_labels)\n",
    "\n",
    "# Faire des prédictions sur les données d'entraînement (pour évaluation)\n",
    "train_predictions = dummy_clf.predict(train_numeric)\n",
    "\n",
    "# Calculer le score de précision sur les données d'entraînement\n",
    "train_score = accuracy_score(train_labels, train_predictions)\n",
    "\n",
    "# Faire des prédictions sur les données de test\n",
    "dummy_predictions = dummy_clf.predict(test_numeric)\n",
    "\n",
    "# Créer le DataFrame de soumission\n",
    "submit = app_test[['SK_ID_CURR']].copy()\n",
    "submit['TARGET'] = dummy_predictions\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Score du modèle sur les données d'entraînement :\", train_score)\n",
    "print(submit.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea41e78-baae-4eea-8a95-7de5c90ac703",
   "metadata": {},
   "source": [
    "# Regression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e99ecb5f-2214-42d0-9c57-b31bfe7656e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.6831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/25/t6v1433n06x6vfl9wjbxn8sw0000gn/T/ipykernel_1249/2695516506.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submit['TARGET'] = log_reg_pred\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>342180</td>\n",
       "      <td>0.081685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259636</td>\n",
       "      <td>0.064739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>305882</td>\n",
       "      <td>0.077060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243264</td>\n",
       "      <td>0.063606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>264946</td>\n",
       "      <td>0.064830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR    TARGET\n",
       "0      342180  0.081685\n",
       "1      259636  0.064739\n",
       "2      305882  0.077060\n",
       "3      243264  0.063606\n",
       "4      264946  0.064830"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# Charger les données\n",
    "app_train = pd.read_csv('data/application_train_split.csv')\n",
    "app_test = pd.read_csv('data/application_test_split.csv')\n",
    "\n",
    "# Drop the target from the training data\n",
    "if 'TARGET' in app_train:\n",
    "    train = app_train.drop(columns=['TARGET'])\n",
    "    train_labels = app_train['TARGET']\n",
    "else:\n",
    "    train = app_train.copy()\n",
    "\n",
    "# Séparer les colonnes numériques et non numériques\n",
    "numeric_cols = train.select_dtypes(include=['number']).columns\n",
    "categorical_cols = train.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# Imputation des valeurs manquantes pour les colonnes numériques\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "train_numeric = imputer.fit_transform(train[numeric_cols])\n",
    "test_numeric = imputer.transform(app_test[numeric_cols])\n",
    "\n",
    "# Normalisation des colonnes numériques\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_numeric = scaler.fit_transform(train_numeric)\n",
    "test_numeric = scaler.transform(test_numeric)\n",
    "train_final = pd.DataFrame(train_numeric, columns=numeric_cols)\n",
    "test_final = pd.DataFrame(test_numeric, columns=numeric_cols)\n",
    "\n",
    "# Créer et entraîner le modèle\n",
    "log_reg = LogisticRegression(C=0.0001)\n",
    "log_reg.fit(train_final, train_labels)\n",
    "\n",
    "# Faire des prédictions sur les données d'entraînement\n",
    "train_pred = log_reg.predict_proba(train_final)[:, 1]\n",
    "\n",
    "# Calculer le score ROC AUC sur les données d'entraînement\n",
    "roc_auc = roc_auc_score(train_labels, train_pred)\n",
    "\n",
    "# Afficher le score ROC AUC\n",
    "print(f'ROC AUC Score: {roc_auc:.4f}')\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "log_reg_pred = log_reg.predict_proba(test_final)[:, 1]\n",
    "\n",
    "# Créer le DataFrame de soumission\n",
    "submit = app_test[['SK_ID_CURR']]\n",
    "submit['TARGET'] = log_reg_pred\n",
    "\n",
    "submit.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c2c450-e5a0-4033-9b03-f285c73c2d49",
   "metadata": {},
   "source": [
    "# Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "736f2891-4329-4793-9279-a4e274a87c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.7277\n",
      "Prédictions:\n",
      "   SK_ID_CURR    TARGET\n",
      "0      342180  0.045878\n",
      "1      259636  0.079470\n",
      "2      305882  0.045878\n",
      "3      243264  0.037365\n",
      "4      264946  0.061666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# Charger les données\n",
    "app_train = pd.read_csv('data/application_train_split.csv')\n",
    "app_test = pd.read_csv('data/application_test_split.csv')\n",
    "\n",
    "# Convertir toutes les colonnes en numériques en utilisant LabelEncoder\n",
    "label_encoders = {}\n",
    "for col in app_train.columns:\n",
    "    if app_train[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        app_train[col] = le.fit_transform(app_train[col].astype(str))\n",
    "        if col in app_test.columns:\n",
    "            app_test[col] = le.transform(app_test[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Séparer les données d'entraînement et les labels\n",
    "if 'TARGET' in app_train:\n",
    "    train = app_train.drop(columns=['TARGET'])\n",
    "    train_labels = app_train['TARGET']\n",
    "else:\n",
    "    train = app_train.copy()\n",
    "    train_labels = None\n",
    "\n",
    "# Préparer les données de test sans l'identifiant\n",
    "test = app_test.drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "# S'assurer que les colonnes sont alignées avant l'imputation\n",
    "common_cols = train.columns.intersection(test.columns)\n",
    "train = train[common_cols]\n",
    "test = test[common_cols]\n",
    "\n",
    "# Imputer les valeurs manquantes avec la médiane\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "train = imputer.fit_transform(train)\n",
    "test = imputer.transform(test)\n",
    "\n",
    "# Créer le modèle d'Arbre de Décision avec des hyperparamètres\n",
    "decision_tree = DecisionTreeClassifier(max_depth=7, min_samples_split=10, min_samples_leaf=5)\n",
    "\n",
    "# Entraîner le modèle\n",
    "decision_tree.fit(train, train_labels)\n",
    "\n",
    "# Faire des prédictions sur les données d'entraînement\n",
    "train_pred = decision_tree.predict_proba(train)[:, 1]\n",
    "\n",
    "# Calculer le score ROC AUC sur les données d'entraînement\n",
    "roc_auc = roc_auc_score(train_labels, train_pred)\n",
    "\n",
    "# Afficher le score ROC AUC\n",
    "print(f'ROC AUC Score: {roc_auc:.4f}')\n",
    "\n",
    "# Extraire l'importance des caractéristiques\n",
    "feature_importance_values = decision_tree.feature_importances_\n",
    "feature_importances = pd.DataFrame({'feature': common_cols, 'importance': feature_importance_values})\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = decision_tree.predict_proba(test)[:, 1]\n",
    "\n",
    "# Créer le DataFrame de soumission\n",
    "submit = pd.DataFrame({'SK_ID_CURR': app_test['SK_ID_CURR'], 'TARGET': predictions})\n",
    "\n",
    "print(\"Prédictions:\")\n",
    "print(submit.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f90fe8-b379-4fb2-9f90-1e169a65c26f",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39a5bcdf-cab0-4821-94cb-cfe584d40f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.8297\n",
      "Prédictions:\n",
      "   SK_ID_CURR  TARGET\n",
      "0      342180     0.0\n",
      "1      259636     0.0\n",
      "2      305882     0.0\n",
      "3      243264     0.0\n",
      "4      264946     0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# Charger les données\n",
    "app_train = pd.read_csv('data/application_train_split.csv')\n",
    "app_test = pd.read_csv('data/application_test_split.csv')\n",
    "\n",
    "# Convertir toutes les colonnes en numériques en utilisant LabelEncoder\n",
    "label_encoders = {}\n",
    "for col in app_train.columns:\n",
    "    if app_train[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        app_train[col] = le.fit_transform(app_train[col].astype(str))\n",
    "        if col in app_test.columns:\n",
    "            app_test[col] = le.transform(app_test[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Séparer les données d'entraînement et les labels\n",
    "if 'TARGET' in app_train:\n",
    "    train = app_train.drop(columns=['TARGET'])\n",
    "    train_labels = app_train['TARGET']\n",
    "else:\n",
    "    train = app_train.copy()\n",
    "    train_labels = None\n",
    "\n",
    "# Préparer les données de test sans l'identifiant\n",
    "test = app_test.drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "# S'assurer que les colonnes sont alignées avant l'imputation\n",
    "common_cols = train.columns.intersection(test.columns)\n",
    "train = train[common_cols]\n",
    "test = test[common_cols]\n",
    "\n",
    "# Imputer les valeurs manquantes avec la médiane\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "train = imputer.fit_transform(train)\n",
    "test = imputer.transform(test)\n",
    "\n",
    "# Créer le modèle RandomForest\n",
    "random_forest = RandomForestClassifier(n_estimators=1, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Entraîner le modèle\n",
    "random_forest.fit(train, train_labels)\n",
    "\n",
    "# Faire des prédictions sur les données d'entraînement\n",
    "train_pred = random_forest.predict_proba(train)[:, 1]\n",
    "\n",
    "# Calculer le score ROC AUC sur les données d'entraînement\n",
    "roc_auc = roc_auc_score(train_labels, train_pred)\n",
    "\n",
    "# Afficher le score ROC AUC\n",
    "print(f'ROC AUC Score: {roc_auc:.4f}')\n",
    "\n",
    "# Extraire l'importance des caractéristiques\n",
    "feature_importance_values = random_forest.feature_importances_\n",
    "feature_importances = pd.DataFrame({'feature': common_cols, 'importance': feature_importance_values})\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = random_forest.predict_proba(test)[:, 1]\n",
    "\n",
    "# Créer le DataFrame de soumission\n",
    "submit = pd.DataFrame({'SK_ID_CURR': app_test['SK_ID_CURR'], 'TARGET': predictions})\n",
    "\n",
    "print(\"Prédictions:\")\n",
    "print(submit.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3280e2-9c4d-4a95-a881-29af62b8a4b0",
   "metadata": {},
   "source": [
    "# Fonction unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f86fc626-f1e5-4404-8dd1-34e35c790219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores ROC AUC des modèles :\n",
      "                 Model  ROC AUC Score\n",
      "       DummyClassifier       0.852316\n",
      "    LogisticRegression       0.685603\n",
      "DecisionTreeClassifier       0.727685\n",
      "RandomForestClassifier       0.830694\n",
      "    CatBoostClassifier       0.768578\n",
      "    LightGBMClassifier       0.798777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "def process_and_predict(train_file, test_file):\n",
    "    # Configurer le logging pour ignorer les messages d'information de LightGBM\n",
    "    logging.getLogger('lightgbm').setLevel(logging.ERROR)\n",
    "    \n",
    "    # Rediriger stdout pour éviter les messages d'information de LightGBM\n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = open('/dev/null', 'w')  # Sur Unix/Linux/Mac\n",
    "    # sys.stdout = open(os.devnull, 'w')  # Sur Windows\n",
    "    \n",
    "    # Charger les données\n",
    "    app_train = pd.read_csv(train_file)\n",
    "    app_test = pd.read_csv(test_file)\n",
    "    \n",
    "    # Convertir toutes les colonnes en numériques en utilisant LabelEncoder\n",
    "    label_encoders = {}\n",
    "    for col in app_train.columns:\n",
    "        if app_train[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            app_train[col] = le.fit_transform(app_train[col].astype(str))\n",
    "            if col in app_test.columns:\n",
    "                app_test[col] = le.transform(app_test[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    # Séparer les données d'entraînement et les labels\n",
    "    if 'TARGET' in app_train:\n",
    "        train = app_train.drop(columns=['TARGET'])\n",
    "        train_labels = app_train['TARGET']\n",
    "    else:\n",
    "        raise ValueError(\"La colonne 'TARGET' n'existe pas dans les données d'entraînement.\")\n",
    "    \n",
    "    # Préparer les données de test sans l'identifiant\n",
    "    test = app_test.drop(columns=['SK_ID_CURR'])\n",
    "    \n",
    "    # S'assurer que les colonnes sont alignées avant l'imputation\n",
    "    common_cols = train.columns.intersection(test.columns)\n",
    "    train = train[common_cols]\n",
    "    test = test[common_cols]\n",
    "    \n",
    "    # Imputer les valeurs manquantes avec la médiane\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    train_numeric = imputer.fit_transform(train)\n",
    "    test_numeric = imputer.transform(test)\n",
    "    \n",
    "    # Normaliser les colonnes numériques\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_numeric = scaler.fit_transform(train_numeric)\n",
    "    test_numeric = scaler.transform(test_numeric)\n",
    "    \n",
    "    # Convertir les matrices numpy en DataFrames pandas\n",
    "    train_final = pd.DataFrame(train_numeric, columns=common_cols)\n",
    "    test_final = pd.DataFrame(test_numeric, columns=common_cols)\n",
    "    \n",
    "    # Créer et entraîner le DummyClassifier\n",
    "    dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "    dummy_clf.fit(train_final, train_labels)\n",
    "    dummy_predictions = dummy_clf.predict(test_final)\n",
    "    dummy_score = dummy_clf.score(train_final, train_labels)\n",
    "    \n",
    "    # Créer et entraîner le modèle LogisticRegression\n",
    "    log_reg = LogisticRegression(C=0.0001, max_iter=1000)\n",
    "    log_reg.fit(train_final, train_labels)\n",
    "    train_pred_log_reg = log_reg.predict_proba(train_final)[:, 1]\n",
    "    roc_auc_log_reg = roc_auc_score(train_labels, train_pred_log_reg)\n",
    "    \n",
    "    # Créer et entraîner le modèle DecisionTreeClassifier\n",
    "    decision_tree = DecisionTreeClassifier(max_depth=7, min_samples_split=10, min_samples_leaf=5)\n",
    "    decision_tree.fit(train_final, train_labels)\n",
    "    train_pred_tree = decision_tree.predict_proba(train_final)[:, 1]\n",
    "    roc_auc_tree = roc_auc_score(train_labels, train_pred_tree)\n",
    "    \n",
    "    # Créer et entraîner le modèle RandomForestClassifier\n",
    "    random_forest = RandomForestClassifier(n_estimators=1, verbose=1, n_jobs=-1)\n",
    "    random_forest.fit(train_final, train_labels)\n",
    "    train_pred_rf = random_forest.predict_proba(train_final)[:, 1]\n",
    "    roc_auc_rf = roc_auc_score(train_labels, train_pred_rf)\n",
    "    \n",
    "    # Créer et entraîner le modèle CatBoostClassifier\n",
    "    catboost_model = CatBoostClassifier(iterations=100, depth=7, learning_rate=0.1, loss_function='Logloss', verbose=0)\n",
    "    catboost_model.fit(train_final, train_labels)\n",
    "    train_pred_catboost = catboost_model.predict_proba(train_final)[:, 1]\n",
    "    roc_auc_catboost = roc_auc_score(train_labels, train_pred_catboost)\n",
    "    catboost_predictions = catboost_model.predict_proba(test_final)[:, 1]\n",
    "    \n",
    "    # Créer et entraîner le modèle LightGBMClassifier\n",
    "    lightgbm_model = lgb.LGBMClassifier(n_estimators=100, max_depth=7, learning_rate=0.1)\n",
    "    lightgbm_model.fit(train_final, train_labels)\n",
    "    train_pred_lightgbm = lightgbm_model.predict_proba(train_final)[:, 1]\n",
    "    roc_auc_lightgbm = roc_auc_score(train_labels, train_pred_lightgbm)\n",
    "    lightgbm_predictions = lightgbm_model.predict_proba(test_final)[:, 1]\n",
    "    \n",
    "    # Rétablir stdout\n",
    "    sys.stdout = original_stdout\n",
    "    \n",
    "    # Afficher les résultats dans un tableau lisible\n",
    "    results = {\n",
    "        'Model': ['DummyClassifier', 'LogisticRegression', 'DecisionTreeClassifier', 'RandomForestClassifier', 'CatBoostClassifier', 'LightGBMClassifier'],\n",
    "        'ROC AUC Score': [dummy_score, roc_auc_log_reg, roc_auc_tree, roc_auc_rf, roc_auc_catboost, roc_auc_lightgbm]\n",
    "    }\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    print(\"Scores ROC AUC des modèles :\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    return {\n",
    "        'DummyClassifier': dummy_predictions,\n",
    "        'LogisticRegression': log_reg.predict_proba(test_final)[:, 1],\n",
    "        'DecisionTreeClassifier': decision_tree.predict_proba(test_final)[:, 1],\n",
    "        'RandomForestClassifier': random_forest.predict_proba(test_final)[:, 1],\n",
    "        'CatBoostClassifier': catboost_predictions,\n",
    "        'LightGBMClassifier': lightgbm_predictions\n",
    "    }\n",
    "\n",
    "# Appel de la fonction avec les chemins des fichiers\n",
    "predictions = process_and_predict('data/application_train_split.csv', 'data/application_test_split.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aa68fa-883d-4539-9147-9e08c52d76df",
   "metadata": {},
   "source": [
    "# Fonction unique avec CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "48e3b723-6652-4338-89b6-3b3c91cbec26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres pour chaque modèle :\n",
      "LogisticRegression: {'C': 10}\n",
      "DecisionTreeClassifier: {'max_depth': 7, 'min_samples_split': 50}\n",
      "RandomForestClassifier: {'max_depth': 10, 'n_estimators': 100}\n",
      "CatBoostClassifier: {'depth': 6, 'learning_rate': 0.3}\n",
      "LightGBMClassifier: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'num_leaves': 63}\n",
      "Résultats des modèles :\n",
      "+------------------------+-----------+-------------+----------+------------+--------------------------------------------+---------------------------------+\n",
      "| Model                  |   ROC AUC |   Precision |   Recall |   F1 Score | Confusion Matrix                           | Time for 1000 Predictions (s)   |\n",
      "+========================+===========+=============+==========+============+============================================+=================================+\n",
      "| DummyClassifier        |   0.50101 |     0.08438 |  0.08472 |    0.08455 | TN: 182069, FP: 15896, FN: 15827, TP: 1465 | 1.15 s                          |\n",
      "+------------------------+-----------+-------------+----------+------------+--------------------------------------------+---------------------------------+\n",
      "| LogisticRegression     |   0.74677 |     0.44094 |  0.00972 |    0.01901 | TN: 197752, FP: 213, FN: 17124, TP: 168    | 4.26 s                          |\n",
      "+------------------------+-----------+-------------+----------+------------+--------------------------------------------+---------------------------------+\n",
      "| DecisionTreeClassifier |   0.72603 |     0.72028 |  0.01191 |    0.02344 | TN: 197885, FP: 80, FN: 17086, TP: 206     | 8.74 s                          |\n",
      "+------------------------+-----------+-------------+----------+------------+--------------------------------------------+---------------------------------+\n",
      "| RandomForestClassifier |   0.81423 |     0       |  0       |    0       | TN: 197965, FP: 0, FN: 17292, TP: 0        | 54.67 s                         |\n",
      "+------------------------+-----------+-------------+----------+------------+--------------------------------------------+---------------------------------+\n",
      "| CatBoostClassifier     |   0.78269 |     0.77633 |  0.04135 |    0.07852 | TN: 197759, FP: 206, FN: 16577, TP: 715    | 7.25 s                          |\n",
      "+------------------------+-----------+-------------+----------+------------+--------------------------------------------+---------------------------------+\n",
      "| LightGBMClassifier     |   0.81298 |     0.7648  |  0.02689 |    0.05196 | TN: 197822, FP: 143, FN: 16827, TP: 465    | 44.11 s                         |\n",
      "+------------------------+-----------+-------------+----------+------------+--------------------------------------------+---------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "\n",
    "def measure_prediction_time(model, X, n_predictions=1000):\n",
    "    \"\"\"Mesurer le temps de prédiction moyen sur n_predictions échantillons.\"\"\"\n",
    "    start_time = time.time()\n",
    "    for _ in range(n_predictions):\n",
    "        _ = model.predict_proba(X)[:, 1]\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    return \"{:.2f} s\".format(elapsed_time)\n",
    "\n",
    "def process_and_predict(train_file, test_file):\n",
    "    # Configurer le logging pour ignorer les messages d'information de LightGBM\n",
    "    logging.getLogger('lightgbm').setLevel(logging.ERROR)\n",
    "    \n",
    "    # Rediriger stdout pour éviter les messages d'information de LightGBM\n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = open('/dev/null', 'w')  # Sur Unix/Linux/Mac\n",
    "    \n",
    "    # Charger les données\n",
    "    app_train = pd.read_csv(train_file)\n",
    "    app_test = pd.read_csv(test_file)\n",
    "    \n",
    "    # Convertir toutes les colonnes en numériques en utilisant LabelEncoder\n",
    "    label_encoders = {}\n",
    "    for col in app_train.columns:\n",
    "        if app_train[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            app_train[col] = le.fit_transform(app_train[col].astype(str))\n",
    "            if col in app_test.columns:\n",
    "                app_test[col] = le.transform(app_test[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    # Séparer les données d'entraînement et les labels\n",
    "    if 'TARGET' in app_train:\n",
    "        train = app_train.drop(columns=['TARGET'])\n",
    "        train_labels = app_train['TARGET']\n",
    "    else:\n",
    "        raise ValueError(\"La colonne 'TARGET' n'existe pas dans les données d'entraînement.\")\n",
    "    \n",
    "    # Préparer les données de test sans l'identifiant\n",
    "    test = app_test.drop(columns=['SK_ID_CURR'])\n",
    "    \n",
    "    # S'assurer que les colonnes sont alignées avant l'imputation\n",
    "    common_cols = train.columns.intersection(test.columns)\n",
    "    train = train[common_cols]\n",
    "    test = test[common_cols]\n",
    "    \n",
    "    # Imputer les valeurs manquantes avec la médiane\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    train_numeric = imputer.fit_transform(train)\n",
    "    test_numeric = imputer.transform(test)\n",
    "    \n",
    "    # Normaliser les colonnes numériques\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_numeric = scaler.fit_transform(train_numeric)\n",
    "    test_numeric = scaler.transform(test_numeric)\n",
    "    \n",
    "    # Convertir les matrices numpy en DataFrames pandas\n",
    "    train_final = pd.DataFrame(train_numeric, columns=common_cols)\n",
    "    test_final = pd.DataFrame(test_numeric, columns=common_cols)\n",
    "    \n",
    "    # Créer et entraîner le DummyClassifier\n",
    "    dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "    dummy_clf.fit(train_final, train_labels)\n",
    "    dummy_predictions = dummy_clf.predict_proba(test_final)[:, 1]\n",
    "    dummy_auc = roc_auc_score(train_labels, dummy_clf.predict_proba(train_final)[:, 1])\n",
    "    dummy_time = measure_prediction_time(dummy_clf, test_final)\n",
    "    \n",
    "    # Définir les paramètres pour GridSearchCV pour LogisticRegression\n",
    "    log_reg_params = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "    log_reg = LogisticRegression(max_iter=2000)  # Augmenté à 2000\n",
    "    log_reg_grid = GridSearchCV(log_reg, log_reg_params, cv=5, scoring='roc_auc')\n",
    "    log_reg_grid.fit(train_final, train_labels)\n",
    "    log_reg_auc = roc_auc_score(train_labels, log_reg_grid.predict_proba(train_final)[:, 1])\n",
    "    log_reg_time = measure_prediction_time(log_reg_grid, test_final)\n",
    "    \n",
    "    # Définir les paramètres pour GridSearchCV pour DecisionTreeClassifier\n",
    "    tree_params = {'max_depth': [5, 7, 10], 'min_samples_split': [10, 20, 50]}\n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    tree_grid = GridSearchCV(decision_tree, tree_params, cv=5, scoring='roc_auc')\n",
    "    tree_grid.fit(train_final, train_labels)\n",
    "    tree_auc = roc_auc_score(train_labels, tree_grid.predict_proba(train_final)[:, 1])\n",
    "    tree_time = measure_prediction_time(tree_grid, test_final)\n",
    "    \n",
    "    # Définir les paramètres pour GridSearchCV pour RandomForestClassifier\n",
    "    rf_params = {'n_estimators': [10, 50, 100], 'max_depth': [5, 7, 10]}\n",
    "    random_forest = RandomForestClassifier(n_jobs=-1)\n",
    "    rf_grid = GridSearchCV(random_forest, rf_params, cv=5, scoring='roc_auc')\n",
    "    rf_grid.fit(train_final, train_labels)\n",
    "    rf_auc = roc_auc_score(train_labels, rf_grid.predict_proba(train_final)[:, 1])\n",
    "    rf_time = measure_prediction_time(rf_grid, test_final)\n",
    "    \n",
    "    # Définir les paramètres pour GridSearchCV pour CatBoostClassifier\n",
    "    catboost_params = {'depth': [6, 7, 8], 'learning_rate': [0.01, 0.1, 0.3]}\n",
    "    catboost_model = CatBoostClassifier(iterations=100, loss_function='Logloss', verbose=0)\n",
    "    catboost_grid = GridSearchCV(catboost_model, catboost_params, cv=5, scoring='roc_auc')\n",
    "    catboost_grid.fit(train_final, train_labels)\n",
    "    catboost_auc = roc_auc_score(train_labels, catboost_grid.predict_proba(train_final)[:, 1])\n",
    "    catboost_predictions = catboost_grid.predict_proba(test_final)[:, 1]\n",
    "    catboost_time = measure_prediction_time(catboost_grid, test_final)\n",
    "    \n",
    "    # Définir les paramètres pour GridSearchCV pour LightGBMClassifier\n",
    "    lightgbm_params = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'max_depth': [6, 7, 8],\n",
    "        'num_leaves': [2**6 - 1, 2**7 - 1, 2**8 - 1]  # Ajusté pour respecter la condition\n",
    "    }\n",
    "    lightgbm_model = lgb.LGBMClassifier()\n",
    "    lightgbm_grid = GridSearchCV(lightgbm_model, lightgbm_params, cv=5, scoring='roc_auc')\n",
    "    lightgbm_grid.fit(train_final, train_labels)\n",
    "    lightgbm_auc = roc_auc_score(train_labels, lightgbm_grid.predict_proba(train_final)[:, 1])\n",
    "    lightgbm_predictions = lightgbm_grid.predict_proba(test_final)[:, 1]\n",
    "    lightgbm_time = measure_prediction_time(lightgbm_grid, test_final)\n",
    "    \n",
    "    # Rétablir stdout\n",
    "    sys.stdout = original_stdout\n",
    "\n",
    "    # Afficher les meilleurs hyperparamètres pour chaque modèle\n",
    "    best_params = {\n",
    "        'LogisticRegression': log_reg_grid.best_params_,\n",
    "        'DecisionTreeClassifier': tree_grid.best_params_,\n",
    "        'RandomForestClassifier': rf_grid.best_params_,\n",
    "        'CatBoostClassifier': catboost_grid.best_params_,\n",
    "        'LightGBMClassifier': lightgbm_grid.best_params_\n",
    "    }\n",
    "    \n",
    "    print(\"Meilleurs hyperparamètres pour chaque modèle :\")\n",
    "    for model_name, params in best_params.items():\n",
    "        print(f\"{model_name}: {params}\")\n",
    "    \n",
    "    # Calcul des métriques pour chaque modèle\n",
    "    models = {\n",
    "        'DummyClassifier': dummy_clf,\n",
    "        'LogisticRegression': log_reg_grid,\n",
    "        'DecisionTreeClassifier': tree_grid,\n",
    "        'RandomForestClassifier': rf_grid,\n",
    "        'CatBoostClassifier': catboost_grid,\n",
    "        'LightGBMClassifier': lightgbm_grid\n",
    "    }\n",
    "\n",
    "    metrics = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        train_pred = model.predict(train_final)\n",
    "        auc_score = roc_auc_score(train_labels, model.predict_proba(train_final)[:, 1])\n",
    "        precision = precision_score(train_labels, train_pred, zero_division=0)\n",
    "        recall = recall_score(train_labels, train_pred, zero_division=0)\n",
    "        f1 = f1_score(train_labels, train_pred, zero_division=0)\n",
    "        cm = confusion_matrix(train_labels, train_pred)\n",
    "        cm_str = f\"TN: {cm[0, 0]}, FP: {cm[0, 1]}, FN: {cm[1, 0]}, TP: {cm[1, 1]}\"\n",
    "        time_metric = measure_prediction_time(model, test_final)\n",
    "        metrics.append([\n",
    "            name,\n",
    "            f\"{auc_score:.5f}\",\n",
    "            f\"{precision:.5f}\",\n",
    "            f\"{recall:.5f}\",\n",
    "            f\"{f1:.5f}\",\n",
    "            cm_str,\n",
    "            time_metric\n",
    "        ])\n",
    "    \n",
    "    # Affichage des résultats\n",
    "    headers = ['Model', 'ROC AUC', 'Precision', 'Recall', 'F1 Score', 'Confusion Matrix', 'Time for 1000 Predictions (s)']\n",
    "    results_table = tabulate(metrics, headers, tablefmt='grid')\n",
    "    \n",
    "    print(\"Résultats des modèles :\")\n",
    "    print(results_table)\n",
    "    \n",
    "    return {\n",
    "        'DummyClassifier': dummy_predictions,\n",
    "        'LogisticRegression': log_reg_grid.predict_proba(test_final)[:, 1],\n",
    "        'DecisionTreeClassifier': tree_grid.predict_proba(test_final)[:, 1],\n",
    "        'RandomForestClassifier': rf_grid.predict_proba(test_final)[:, 1],\n",
    "        'CatBoostClassifier': catboost_predictions,\n",
    "        'LightGBMClassifier': lightgbm_predictions\n",
    "    }\n",
    "\n",
    "# Appel de la fonction avec les chemins des fichiers\n",
    "predictions = process_and_predict('data/application_train_split.csv', 'data/application_test_split.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9799e612-f105-42a5-9376-033f20992022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
