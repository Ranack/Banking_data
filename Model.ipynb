{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d31b987a-dff1-476c-b26c-a57e68cacee1",
   "metadata": {},
   "source": [
    "# Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a6d85fae-0e56-4a49-9bf7-ddd4681c4efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions : [0 0 0 ... 0 0 0]\n",
      "Score du modèle : 0.8541531171606429\n",
      "   SK_ID_CURR  TARGET\n",
      "0      342180       0\n",
      "1      259636       0\n",
      "2      305882       0\n",
      "3      243264       0\n",
      "4      264946       0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Lire les données\n",
    "app_train = pd.read_csv('data/application_train_split.csv')\n",
    "app_test = pd.read_csv('data/application_test_split.csv')\n",
    "\n",
    "# Séparer les données d'entraînement\n",
    "if 'TARGET' in app_train:\n",
    "    train = app_train.drop(columns=['TARGET'])\n",
    "    train_labels = app_train['TARGET']\n",
    "else:\n",
    "    raise ValueError(\"La colonne 'TARGET' n'existe pas dans les données d'entraînement.\")\n",
    "\n",
    "# Préparer les colonnes numériques\n",
    "numeric_cols = train.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Imputer les valeurs manquantes pour les colonnes numériques\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "train_numeric = imputer.fit_transform(train[numeric_cols])\n",
    "test_numeric = imputer.transform(app_test[numeric_cols])\n",
    "\n",
    "# Normaliser les colonnes numériques\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_numeric = scaler.fit_transform(train_numeric)\n",
    "test_numeric = scaler.transform(test_numeric)\n",
    "\n",
    "# Créer et entraîner le DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "dummy_clf.fit(train_numeric, train_labels)\n",
    "\n",
    "# Faire des prédictions sur les données de test\n",
    "dummy_predictions = dummy_clf.predict(test_numeric)\n",
    "\n",
    "# Créer le DataFrame de soumission\n",
    "submit = app_test[['SK_ID_CURR']].copy()\n",
    "submit['TARGET'] = dummy_predictions\n",
    "# Faire des prédictions et évaluer le modèle\n",
    "dummy_predictions = dummy_clf.predict(X_test)\n",
    "dummy_score = dummy_clf.score(X_test, y_test)\n",
    "\n",
    "print(\"Prédictions :\", dummy_predictions)\n",
    "print(\"Score du modèle :\", dummy_score)\n",
    "print(submit.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea41e78-baae-4eea-8a95-7de5c90ac703",
   "metadata": {},
   "source": [
    "# Regression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e99ecb5f-2214-42d0-9c57-b31bfe7656e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.6831\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>342180</td>\n",
       "      <td>0.081685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259636</td>\n",
       "      <td>0.064739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>305882</td>\n",
       "      <td>0.077060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243264</td>\n",
       "      <td>0.063606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>264946</td>\n",
       "      <td>0.064830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR    TARGET\n",
       "0      342180  0.081685\n",
       "1      259636  0.064739\n",
       "2      305882  0.077060\n",
       "3      243264  0.063606\n",
       "4      264946  0.064830"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# Charger les données\n",
    "app_train = pd.read_csv('data/application_train_split.csv')\n",
    "app_test = pd.read_csv('data/application_test_split.csv')\n",
    "\n",
    "# Drop the target from the training data\n",
    "if 'TARGET' in app_train:\n",
    "    train = app_train.drop(columns=['TARGET'])\n",
    "    train_labels = app_train['TARGET']\n",
    "else:\n",
    "    train = app_train.copy()\n",
    "\n",
    "# Séparer les colonnes numériques et non numériques\n",
    "numeric_cols = train.select_dtypes(include=['number']).columns\n",
    "categorical_cols = train.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# Imputation des valeurs manquantes pour les colonnes numériques\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "train_numeric = imputer.fit_transform(train[numeric_cols])\n",
    "test_numeric = imputer.transform(app_test[numeric_cols])\n",
    "\n",
    "# Normalisation des colonnes numériques\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_numeric = scaler.fit_transform(train_numeric)\n",
    "test_numeric = scaler.transform(test_numeric)\n",
    "train_final = pd.DataFrame(train_numeric, columns=numeric_cols)\n",
    "test_final = pd.DataFrame(test_numeric, columns=numeric_cols)\n",
    "\n",
    "# Créer et entraîner le modèle\n",
    "log_reg = LogisticRegression(C=0.0001)\n",
    "log_reg.fit(train_final, train_labels)\n",
    "\n",
    "# Faire des prédictions sur les données d'entraînement\n",
    "train_pred = log_reg.predict_proba(train_final)[:, 1]\n",
    "\n",
    "# Calculer le score ROC AUC sur les données d'entraînement\n",
    "roc_auc = roc_auc_score(train_labels, train_pred)\n",
    "\n",
    "# Afficher le score ROC AUC\n",
    "print(f'ROC AUC Score: {roc_auc:.4f}')\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "log_reg_pred = log_reg.predict_proba(test_final)[:, 1]\n",
    "\n",
    "# Créer le DataFrame de soumission\n",
    "submit = app_test[['SK_ID_CURR']]\n",
    "submit['TARGET'] = log_reg_pred\n",
    "\n",
    "submit.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c2c450-e5a0-4033-9b03-f285c73c2d49",
   "metadata": {},
   "source": [
    "# Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "736f2891-4329-4793-9279-a4e274a87c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.7277\n",
      "Prédictions:\n",
      "   SK_ID_CURR    TARGET\n",
      "0      342180  0.045878\n",
      "1      259636  0.079470\n",
      "2      305882  0.045878\n",
      "3      243264  0.037365\n",
      "4      264946  0.061666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# Charger les données\n",
    "app_train = pd.read_csv('data/application_train_split.csv')\n",
    "app_test = pd.read_csv('data/application_test_split.csv')\n",
    "\n",
    "# Convertir toutes les colonnes en numériques en utilisant LabelEncoder\n",
    "label_encoders = {}\n",
    "for col in app_train.columns:\n",
    "    if app_train[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        app_train[col] = le.fit_transform(app_train[col].astype(str))\n",
    "        if col in app_test.columns:\n",
    "            app_test[col] = le.transform(app_test[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Séparer les données d'entraînement et les labels\n",
    "if 'TARGET' in app_train:\n",
    "    train = app_train.drop(columns=['TARGET'])\n",
    "    train_labels = app_train['TARGET']\n",
    "else:\n",
    "    train = app_train.copy()\n",
    "    train_labels = None\n",
    "\n",
    "# Préparer les données de test sans l'identifiant\n",
    "test = app_test.drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "# S'assurer que les colonnes sont alignées avant l'imputation\n",
    "common_cols = train.columns.intersection(test.columns)\n",
    "train = train[common_cols]\n",
    "test = test[common_cols]\n",
    "\n",
    "# Imputer les valeurs manquantes avec la médiane\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "train = imputer.fit_transform(train)\n",
    "test = imputer.transform(test)\n",
    "\n",
    "# Créer le modèle d'Arbre de Décision avec des hyperparamètres\n",
    "decision_tree = DecisionTreeClassifier(max_depth=7, min_samples_split=10, min_samples_leaf=5)\n",
    "\n",
    "# Entraîner le modèle\n",
    "decision_tree.fit(train, train_labels)\n",
    "\n",
    "# Faire des prédictions sur les données d'entraînement\n",
    "train_pred = decision_tree.predict_proba(train)[:, 1]\n",
    "\n",
    "# Calculer le score ROC AUC sur les données d'entraînement\n",
    "roc_auc = roc_auc_score(train_labels, train_pred)\n",
    "\n",
    "# Afficher le score ROC AUC\n",
    "print(f'ROC AUC Score: {roc_auc:.4f}')\n",
    "\n",
    "# Extraire l'importance des caractéristiques\n",
    "feature_importance_values = decision_tree.feature_importances_\n",
    "feature_importances = pd.DataFrame({'feature': common_cols, 'importance': feature_importance_values})\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = decision_tree.predict_proba(test)[:, 1]\n",
    "\n",
    "# Créer le DataFrame de soumission\n",
    "submit = pd.DataFrame({'SK_ID_CURR': app_test['SK_ID_CURR'], 'TARGET': predictions})\n",
    "\n",
    "print(\"Prédictions:\")\n",
    "print(submit.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f90fe8-b379-4fb2-9f90-1e169a65c26f",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "39a5bcdf-cab0-4821-94cb-cfe584d40f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.8294\n",
      "Prédictions:\n",
      "   SK_ID_CURR  TARGET\n",
      "0      342180     0.0\n",
      "1      259636     0.0\n",
      "2      305882     0.0\n",
      "3      243264     0.0\n",
      "4      264946     0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# Charger les données\n",
    "app_train = pd.read_csv('data/application_train_split.csv')\n",
    "app_test = pd.read_csv('data/application_test_split.csv')\n",
    "\n",
    "# Convertir toutes les colonnes en numériques en utilisant LabelEncoder\n",
    "label_encoders = {}\n",
    "for col in app_train.columns:\n",
    "    if app_train[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        app_train[col] = le.fit_transform(app_train[col].astype(str))\n",
    "        if col in app_test.columns:\n",
    "            app_test[col] = le.transform(app_test[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Séparer les données d'entraînement et les labels\n",
    "if 'TARGET' in app_train:\n",
    "    train = app_train.drop(columns=['TARGET'])\n",
    "    train_labels = app_train['TARGET']\n",
    "else:\n",
    "    train = app_train.copy()\n",
    "    train_labels = None\n",
    "\n",
    "# Préparer les données de test sans l'identifiant\n",
    "test = app_test.drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "# S'assurer que les colonnes sont alignées avant l'imputation\n",
    "common_cols = train.columns.intersection(test.columns)\n",
    "train = train[common_cols]\n",
    "test = test[common_cols]\n",
    "\n",
    "# Imputer les valeurs manquantes avec la médiane\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "train = imputer.fit_transform(train)\n",
    "test = imputer.transform(test)\n",
    "\n",
    "# Créer le modèle RandomForest\n",
    "random_forest = RandomForestClassifier(n_estimators=1, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Entraîner le modèle\n",
    "random_forest.fit(train, train_labels)\n",
    "\n",
    "# Faire des prédictions sur les données d'entraînement\n",
    "train_pred = random_forest.predict_proba(train)[:, 1]\n",
    "\n",
    "# Calculer le score ROC AUC sur les données d'entraînement\n",
    "roc_auc = roc_auc_score(train_labels, train_pred)\n",
    "\n",
    "# Afficher le score ROC AUC\n",
    "print(f'ROC AUC Score: {roc_auc:.4f}')\n",
    "\n",
    "# Extraire l'importance des caractéristiques\n",
    "feature_importance_values = random_forest.feature_importances_\n",
    "feature_importances = pd.DataFrame({'feature': common_cols, 'importance': feature_importance_values})\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = random_forest.predict_proba(test)[:, 1]\n",
    "\n",
    "# Créer le DataFrame de soumission\n",
    "submit = pd.DataFrame({'SK_ID_CURR': app_test['SK_ID_CURR'], 'TARGET': predictions})\n",
    "\n",
    "print(\"Prédictions:\")\n",
    "print(submit.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3280e2-9c4d-4a95-a881-29af62b8a4b0",
   "metadata": {},
   "source": [
    "# Fonction unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "f86fc626-f1e5-4404-8dd1-34e35c790219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores ROC AUC des modèles :\n",
      "                 Model  ROC AUC Score\n",
      "       DummyClassifier       0.852376\n",
      "    LogisticRegression       0.685603\n",
      "DecisionTreeClassifier       0.727685\n",
      "RandomForestClassifier       0.823566\n",
      "    CatBoostClassifier       0.768578\n",
      "    LightGBMClassifier       0.798777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "def process_and_predict(train_file, test_file):\n",
    "    # Configurer le logging pour ignorer les messages d'information de LightGBM\n",
    "    logging.getLogger('lightgbm').setLevel(logging.ERROR)\n",
    "    \n",
    "    # Rediriger stdout pour éviter les messages d'information de LightGBM\n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = open('/dev/null', 'w')  # Sur Unix/Linux/Mac\n",
    "    # sys.stdout = open(os.devnull, 'w')  # Sur Windows\n",
    "    \n",
    "    # Charger les données\n",
    "    app_train = pd.read_csv(train_file)\n",
    "    app_test = pd.read_csv(test_file)\n",
    "    \n",
    "    # Convertir toutes les colonnes en numériques en utilisant LabelEncoder\n",
    "    label_encoders = {}\n",
    "    for col in app_train.columns:\n",
    "        if app_train[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            app_train[col] = le.fit_transform(app_train[col].astype(str))\n",
    "            if col in app_test.columns:\n",
    "                app_test[col] = le.transform(app_test[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    # Séparer les données d'entraînement et les labels\n",
    "    if 'TARGET' in app_train:\n",
    "        train = app_train.drop(columns=['TARGET'])\n",
    "        train_labels = app_train['TARGET']\n",
    "    else:\n",
    "        raise ValueError(\"La colonne 'TARGET' n'existe pas dans les données d'entraînement.\")\n",
    "    \n",
    "    # Préparer les données de test sans l'identifiant\n",
    "    test = app_test.drop(columns=['SK_ID_CURR'])\n",
    "    \n",
    "    # S'assurer que les colonnes sont alignées avant l'imputation\n",
    "    common_cols = train.columns.intersection(test.columns)\n",
    "    train = train[common_cols]\n",
    "    test = test[common_cols]\n",
    "    \n",
    "    # Imputer les valeurs manquantes avec la médiane\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    train_numeric = imputer.fit_transform(train)\n",
    "    test_numeric = imputer.transform(test)\n",
    "    \n",
    "    # Normaliser les colonnes numériques\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_numeric = scaler.fit_transform(train_numeric)\n",
    "    test_numeric = scaler.transform(test_numeric)\n",
    "    \n",
    "    # Convertir les matrices numpy en DataFrames pandas\n",
    "    train_final = pd.DataFrame(train_numeric, columns=common_cols)\n",
    "    test_final = pd.DataFrame(test_numeric, columns=common_cols)\n",
    "    \n",
    "    # Créer et entraîner le DummyClassifier\n",
    "    dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "    dummy_clf.fit(train_final, train_labels)\n",
    "    dummy_predictions = dummy_clf.predict(test_final)\n",
    "    dummy_score = dummy_clf.score(train_final, train_labels)\n",
    "    \n",
    "    # Créer et entraîner le modèle LogisticRegression\n",
    "    log_reg = LogisticRegression(C=0.0001, max_iter=1000)\n",
    "    log_reg.fit(train_final, train_labels)\n",
    "    train_pred_log_reg = log_reg.predict_proba(train_final)[:, 1]\n",
    "    roc_auc_log_reg = roc_auc_score(train_labels, train_pred_log_reg)\n",
    "    \n",
    "    # Créer et entraîner le modèle DecisionTreeClassifier\n",
    "    decision_tree = DecisionTreeClassifier(max_depth=7, min_samples_split=10, min_samples_leaf=5)\n",
    "    decision_tree.fit(train_final, train_labels)\n",
    "    train_pred_tree = decision_tree.predict_proba(train_final)[:, 1]\n",
    "    roc_auc_tree = roc_auc_score(train_labels, train_pred_tree)\n",
    "    \n",
    "    # Créer et entraîner le modèle RandomForestClassifier\n",
    "    random_forest = RandomForestClassifier(n_estimators=1, verbose=1, n_jobs=-1)\n",
    "    random_forest.fit(train_final, train_labels)\n",
    "    train_pred_rf = random_forest.predict_proba(train_final)[:, 1]\n",
    "    roc_auc_rf = roc_auc_score(train_labels, train_pred_rf)\n",
    "    \n",
    "    # Créer et entraîner le modèle CatBoostClassifier\n",
    "    catboost_model = CatBoostClassifier(iterations=100, depth=7, learning_rate=0.1, loss_function='Logloss', verbose=0)\n",
    "    catboost_model.fit(train_final, train_labels)\n",
    "    train_pred_catboost = catboost_model.predict_proba(train_final)[:, 1]\n",
    "    roc_auc_catboost = roc_auc_score(train_labels, train_pred_catboost)\n",
    "    catboost_predictions = catboost_model.predict_proba(test_final)[:, 1]\n",
    "    \n",
    "    # Créer et entraîner le modèle LightGBMClassifier\n",
    "    lightgbm_model = lgb.LGBMClassifier(n_estimators=100, max_depth=7, learning_rate=0.1)\n",
    "    lightgbm_model.fit(train_final, train_labels)\n",
    "    train_pred_lightgbm = lightgbm_model.predict_proba(train_final)[:, 1]\n",
    "    roc_auc_lightgbm = roc_auc_score(train_labels, train_pred_lightgbm)\n",
    "    lightgbm_predictions = lightgbm_model.predict_proba(test_final)[:, 1]\n",
    "    \n",
    "    # Rétablir stdout\n",
    "    sys.stdout = original_stdout\n",
    "    \n",
    "    # Afficher les résultats dans un tableau lisible\n",
    "    results = {\n",
    "        'Model': ['DummyClassifier', 'LogisticRegression', 'DecisionTreeClassifier', 'RandomForestClassifier', 'CatBoostClassifier', 'LightGBMClassifier'],\n",
    "        'ROC AUC Score': [dummy_score, roc_auc_log_reg, roc_auc_tree, roc_auc_rf, roc_auc_catboost, roc_auc_lightgbm]\n",
    "    }\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    print(\"Scores ROC AUC des modèles :\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    return {\n",
    "        'DummyClassifier': dummy_predictions,\n",
    "        'LogisticRegression': log_reg.predict_proba(test_final)[:, 1],\n",
    "        'DecisionTreeClassifier': decision_tree.predict_proba(test_final)[:, 1],\n",
    "        'RandomForestClassifier': random_forest.predict_proba(test_final)[:, 1],\n",
    "        'CatBoostClassifier': catboost_predictions,\n",
    "        'LightGBMClassifier': lightgbm_predictions\n",
    "    }\n",
    "\n",
    "# Appel de la fonction avec les chemins des fichiers\n",
    "predictions = process_and_predict('data/application_train_split.csv', 'data/application_test_split.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aa68fa-883d-4539-9147-9e08c52d76df",
   "metadata": {},
   "source": [
    "# Fonction uinique avec CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "c1399437-11df-4b83-9058-e51a450d5c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance Summary:\n",
      "+----+------------------------+-----------------+--------------------+--------------+-------------+-------------+------------+\n",
      "|    | Model                  |   ROC AUC Score | Confusion Matrix   |       Recall |   Precision |    F1 Score |        AUC |\n",
      "+====+========================+=================+====================+==============+=============+=============+============+\n",
      "|  0 | DummyClassifier        |        0.854153 |                    | nan          |  nan        | nan         | nan        |\n",
      "+----+------------------------+-----------------+--------------------+--------------+-------------+-------------+------------+\n",
      "|  1 | LogisticRegression     |        0.746754 | [[39587    41]     |   0.0110981  |    0.481013 |   0.0216957 |   0.746754 |\n",
      "|    |                        |                 |  [ 3386    38]]    |              |             |             |            |\n",
      "+----+------------------------+-----------------+--------------------+--------------+-------------+-------------+------------+\n",
      "|  2 | DecisionTreeClassifier |        0.712011 | [[39513   115]     |   0.0148949  |    0.307229 |   0.0284123 |   0.712011 |\n",
      "|    |                        |                 |  [ 3373    51]]    |              |             |             |            |\n",
      "+----+------------------------+-----------------+--------------------+--------------+-------------+-------------+------------+\n",
      "|  3 | RandomForestClassifier |        0.73696  | [[39628     0]     |   0          |    0        |   0         |   0.73696  |\n",
      "|    |                        |                 |  [ 3424     0]]    |              |             |             |            |\n",
      "+----+------------------------+-----------------+--------------------+--------------+-------------+-------------+------------+\n",
      "|  4 | CatBoostClassifier     |        0.755617 | [[39598    30]     |   0.00905374 |    0.508197 |   0.0177905 |   0.755617 |\n",
      "|    |                        |                 |  [ 3393    31]]    |              |             |             |            |\n",
      "+----+------------------------+-----------------+--------------------+--------------+-------------+-------------+------------+\n",
      "|  5 | LightGBMClassifier     |        0.756888 | [[39584    44]     |   0.0137266  |    0.516484 |   0.0267425 |   0.756888 |\n",
      "|    |                        |                 |  [ 3377    47]]    |              |             |             |            |\n",
      "+----+------------------------+-----------------+--------------------+--------------+-------------+-------------+------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import logging\n",
    "import sys\n",
    "from tabulate import tabulate\n",
    "\n",
    "def process_and_predict(train_file, test_file):\n",
    "    # Configurer le logging pour ignorer les messages d'information de LightGBM\n",
    "    logging.getLogger('lightgbm').setLevel(logging.ERROR)\n",
    "    \n",
    "    # Rediriger stdout pour éviter les messages d'information de LightGBM\n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = open('/dev/null', 'w')  # Sur Unix/Linux/Mac\n",
    "    # sys.stdout = open(os.devnull, 'w')  # Sur Windows\n",
    "    \n",
    "    # Charger les données\n",
    "    app_train = pd.read_csv(train_file)\n",
    "    app_test = pd.read_csv(test_file)\n",
    "    \n",
    "    # Convertir toutes les colonnes en numériques en utilisant LabelEncoder\n",
    "    label_encoders = {}\n",
    "    for col in app_train.columns:\n",
    "        if app_train[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            app_train[col] = le.fit_transform(app_train[col].astype(str))\n",
    "            if col in app_test.columns:\n",
    "                app_test[col] = le.transform(app_test[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    # Séparer les données d'entraînement et les labels\n",
    "    if 'TARGET' in app_train:\n",
    "        train = app_train.drop(columns=['TARGET'])\n",
    "        train_labels = app_train['TARGET']\n",
    "    else:\n",
    "        raise ValueError(\"La colonne 'TARGET' n'existe pas dans les données d'entraînement.\")\n",
    "    \n",
    "    # Préparer les données de test sans l'identifiant\n",
    "    test = app_test.drop(columns=['SK_ID_CURR'])\n",
    "    \n",
    "    # S'assurer que les colonnes sont alignées avant l'imputation\n",
    "    common_cols = train.columns.intersection(test.columns)\n",
    "    train = train[common_cols]\n",
    "    test = test[common_cols]\n",
    "    \n",
    "    # Imputer les valeurs manquantes avec la médiane\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    train_numeric = imputer.fit_transform(train)\n",
    "    test_numeric = imputer.transform(test)\n",
    "    \n",
    "    # Normaliser les colonnes numériques\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_numeric = scaler.fit_transform(train_numeric)\n",
    "    test_numeric = scaler.transform(test_numeric)\n",
    "    \n",
    "    # Convertir les matrices numpy en DataFrames pandas\n",
    "    train_final = pd.DataFrame(train_numeric, columns=common_cols)\n",
    "    test_final = pd.DataFrame(test_numeric, columns=common_cols)\n",
    "    \n",
    "    # Séparer les données pour la validation croisée\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_final, train_labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Définir les hyperparamètres pour GridSearchCV\n",
    "    param_grid_log_reg = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10]\n",
    "    }\n",
    "    \n",
    "    param_grid_decision_tree = {\n",
    "        'max_depth': [5, 7, 10],\n",
    "        'min_samples_split': [2, 10, 20],\n",
    "        'min_samples_leaf': [1, 5, 10]\n",
    "    }\n",
    "    \n",
    "    param_grid_random_forest = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [5, 7, 10],\n",
    "        'min_samples_split': [2, 10],\n",
    "        'min_samples_leaf': [1, 5]\n",
    "    }\n",
    "    \n",
    "    param_grid_catboost = {\n",
    "        'iterations': [50, 100],\n",
    "        'depth': [5, 7],\n",
    "        'learning_rate': [0.01, 0.1]\n",
    "    }\n",
    "    \n",
    "    param_grid_lightgbm = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [5, 7],\n",
    "        'learning_rate': [0.01, 0.1]\n",
    "    }\n",
    "    \n",
    "    # Initialiser les modèles\n",
    "    log_reg = LogisticRegression(max_iter=1000)\n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    random_forest = RandomForestClassifier(n_jobs=-1)\n",
    "    catboost_model = CatBoostClassifier(verbose=0)\n",
    "    lightgbm_model = lgb.LGBMClassifier()\n",
    "    \n",
    "    # GridSearchCV pour chaque modèle\n",
    "    grid_search_log_reg = GridSearchCV(log_reg, param_grid_log_reg, cv=5, scoring='roc_auc')\n",
    "    grid_search_decision_tree = GridSearchCV(decision_tree, param_grid_decision_tree, cv=5, scoring='roc_auc')\n",
    "    grid_search_random_forest = GridSearchCV(random_forest, param_grid_random_forest, cv=5, scoring='roc_auc')\n",
    "    grid_search_catboost = GridSearchCV(catboost_model, param_grid_catboost, cv=5, scoring='roc_auc')\n",
    "    grid_search_lightgbm = GridSearchCV(lightgbm_model, param_grid_lightgbm, cv=5, scoring='roc_auc')\n",
    "    \n",
    "    # Entraîner GridSearchCV pour chaque modèle\n",
    "    grid_search_log_reg.fit(X_train, y_train)\n",
    "    grid_search_decision_tree.fit(X_train, y_train)\n",
    "    grid_search_random_forest.fit(X_train, y_train)\n",
    "    grid_search_catboost.fit(X_train, y_train)\n",
    "    grid_search_lightgbm.fit(X_train, y_train)\n",
    "    \n",
    "    # Meilleurs modèles\n",
    "    best_log_reg = grid_search_log_reg.best_estimator_\n",
    "    best_decision_tree = grid_search_decision_tree.best_estimator_\n",
    "    best_random_forest = grid_search_random_forest.best_estimator_\n",
    "    best_catboost = grid_search_catboost.best_estimator_\n",
    "    best_lightgbm = grid_search_lightgbm.best_estimator_\n",
    "    \n",
    "    # Évaluer les modèles\n",
    "    roc_auc_log_reg = roc_auc_score(y_val, best_log_reg.predict_proba(X_val)[:, 1])\n",
    "    roc_auc_tree = roc_auc_score(y_val, best_decision_tree.predict_proba(X_val)[:, 1])\n",
    "    roc_auc_rf = roc_auc_score(y_val, best_random_forest.predict_proba(X_val)[:, 1])\n",
    "    roc_auc_catboost = roc_auc_score(y_val, best_catboost.predict_proba(X_val)[:, 1])\n",
    "    roc_auc_lightgbm = roc_auc_score(y_val, best_lightgbm.predict_proba(X_val)[:, 1])\n",
    "    \n",
    "    # Faire des prédictions sur l'ensemble de test\n",
    "    catboost_predictions = best_catboost.predict_proba(test_final)[:, 1]\n",
    "    lightgbm_predictions = best_lightgbm.predict_proba(test_final)[:, 1]\n",
    "    \n",
    "    # Calculer les métriques sur les ensembles d'entraînement et de validation\n",
    "    def calculate_metrics(y_true, y_pred_proba):\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "        conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        auc = roc_auc_score(y_true, y_pred_proba)\n",
    "        return conf_matrix, recall, precision, f1, auc\n",
    "    \n",
    "    metrics_log_reg = calculate_metrics(y_val, best_log_reg.predict_proba(X_val)[:, 1])\n",
    "    metrics_tree = calculate_metrics(y_val, best_decision_tree.predict_proba(X_val)[:, 1])\n",
    "    metrics_rf = calculate_metrics(y_val, best_random_forest.predict_proba(X_val)[:, 1])\n",
    "    metrics_catboost = calculate_metrics(y_val, best_catboost.predict_proba(X_val)[:, 1])\n",
    "    metrics_lightgbm = calculate_metrics(y_val, best_lightgbm.predict_proba(X_val)[:, 1])\n",
    "    \n",
    "    # Rétablir stdout\n",
    "    sys.stdout = original_stdout\n",
    "    \n",
    "    # Créer un tableau récapitulatif des performances\n",
    "    results = {\n",
    "        'Model': ['DummyClassifier', 'LogisticRegression', 'DecisionTreeClassifier', 'RandomForestClassifier', 'CatBoostClassifier', 'LightGBMClassifier'],\n",
    "        'ROC AUC Score': [dummy_score, roc_auc_log_reg, roc_auc_tree, roc_auc_rf, roc_auc_catboost, roc_auc_lightgbm],\n",
    "        'Confusion Matrix': [None, metrics_log_reg[0], metrics_tree[0], metrics_rf[0], metrics_catboost[0], metrics_lightgbm[0]],\n",
    "        'Recall': [None, metrics_log_reg[1], metrics_tree[1], metrics_rf[1], metrics_catboost[1], metrics_lightgbm[1]],\n",
    "        'Precision': [None, metrics_log_reg[2], metrics_tree[2], metrics_rf[2], metrics_catboost[2], metrics_lightgbm[2]],\n",
    "        'F1 Score': [None, metrics_log_reg[3], metrics_tree[3], metrics_rf[3], metrics_catboost[3], metrics_lightgbm[3]],\n",
    "        'AUC': [None, metrics_log_reg[4], metrics_tree[4], metrics_rf[4], metrics_catboost[4], metrics_lightgbm[4]]\n",
    "    }\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Afficher le tableau récapitulatif des performances\n",
    "    print(\"\\nPerformance Summary:\")\n",
    "    print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "    \n",
    "    # Créer les DataFrames de soumission\n",
    "    submit_catboost = pd.DataFrame({'SK_ID_CURR': app_test['SK_ID_CURR'], 'TARGET': catboost_predictions})\n",
    "    submit_lightgbm = pd.DataFrame({'SK_ID_CURR': app_test['SK_ID_CURR'], 'TARGET': lightgbm_predictions})\n",
    "    \n",
    "    # Retourner les résultats pour une utilisation ultérieure\n",
    "    return submit_catboost, submit_lightgbm, results_df\n",
    "\n",
    "# Exécuter la fonction\n",
    "submit_catboost, submit_lightgbm, results_summary = process_and_predict('data/application_train_split.csv', 'data/application_test_split.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3d011e-bcbb-4c99-8d1d-894d3e8e02c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde25d2f-d5f7-4b44-a5a0-eaece22dbe77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
