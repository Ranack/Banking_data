{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d31b987a-dff1-476c-b26c-a57e68cacee1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6d85fae-0e56-4a49-9bf7-ddd4681c4efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score du modèle sur les données d'entraînement : 0.8523671704056082\n",
      "   SK_ID_CURR  TARGET\n",
      "0      342180       0\n",
      "1      259636       0\n",
      "2      305882       0\n",
      "3      243264       0\n",
      "4      264946       0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Lire les données\n",
    "app_train = pd.read_csv('data/application_train_split.csv')\n",
    "app_test = pd.read_csv('data/application_test_split.csv')\n",
    "\n",
    "# Séparer les données d'entraînement\n",
    "if 'TARGET' in app_train:\n",
    "    train = app_train.drop(columns=['TARGET'])\n",
    "    train_labels = app_train['TARGET']\n",
    "else:\n",
    "    raise ValueError(\"La colonne 'TARGET' n'existe pas dans les données d'entraînement.\")\n",
    "\n",
    "# Préparer les colonnes numériques\n",
    "numeric_cols = train.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Imputer les valeurs manquantes pour les colonnes numériques\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "train_numeric = imputer.fit_transform(train[numeric_cols])\n",
    "test_numeric = imputer.transform(app_test[numeric_cols])\n",
    "\n",
    "# Normaliser les colonnes numériques\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_numeric = scaler.fit_transform(train_numeric)\n",
    "test_numeric = scaler.transform(test_numeric)\n",
    "\n",
    "# Créer et entraîner le DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "dummy_clf.fit(train_numeric, train_labels)\n",
    "\n",
    "# Faire des prédictions sur les données d'entraînement (pour évaluation)\n",
    "train_predictions = dummy_clf.predict(train_numeric)\n",
    "\n",
    "# Calculer le score de précision sur les données d'entraînement\n",
    "train_score = accuracy_score(train_labels, train_predictions)\n",
    "\n",
    "# Faire des prédictions sur les données de test\n",
    "dummy_predictions = dummy_clf.predict(test_numeric)\n",
    "\n",
    "# Créer le DataFrame de soumission\n",
    "submit = app_test[['SK_ID_CURR']].copy()\n",
    "submit['TARGET'] = dummy_predictions\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Score du modèle sur les données d'entraînement :\", train_score)\n",
    "print(submit.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea41e78-baae-4eea-8a95-7de5c90ac703",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Regression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "e99ecb5f-2214-42d0-9c57-b31bfe7656e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.6831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/25/t6v1433n06x6vfl9wjbxn8sw0000gn/T/ipykernel_43323/2695516506.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submit['TARGET'] = log_reg_pred\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>342180</td>\n",
       "      <td>0.081685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259636</td>\n",
       "      <td>0.064739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>305882</td>\n",
       "      <td>0.077060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243264</td>\n",
       "      <td>0.063606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>264946</td>\n",
       "      <td>0.064830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR    TARGET\n",
       "0      342180  0.081685\n",
       "1      259636  0.064739\n",
       "2      305882  0.077060\n",
       "3      243264  0.063606\n",
       "4      264946  0.064830"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# Charger les données\n",
    "app_train = pd.read_csv('data/application_train_split.csv')\n",
    "app_test = pd.read_csv('data/application_test_split.csv')\n",
    "\n",
    "# Drop the target from the training data\n",
    "if 'TARGET' in app_train:\n",
    "    train = app_train.drop(columns=['TARGET'])\n",
    "    train_labels = app_train['TARGET']\n",
    "else:\n",
    "    train = app_train.copy()\n",
    "\n",
    "# Séparer les colonnes numériques et non numériques\n",
    "numeric_cols = train.select_dtypes(include=['number']).columns\n",
    "categorical_cols = train.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# Imputation des valeurs manquantes pour les colonnes numériques\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "train_numeric = imputer.fit_transform(train[numeric_cols])\n",
    "test_numeric = imputer.transform(app_test[numeric_cols])\n",
    "\n",
    "# Normalisation des colonnes numériques\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_numeric = scaler.fit_transform(train_numeric)\n",
    "test_numeric = scaler.transform(test_numeric)\n",
    "train_final = pd.DataFrame(train_numeric, columns=numeric_cols)\n",
    "test_final = pd.DataFrame(test_numeric, columns=numeric_cols)\n",
    "\n",
    "# Créer et entraîner le modèle\n",
    "log_reg = LogisticRegression(C=0.0001)\n",
    "log_reg.fit(train_final, train_labels)\n",
    "\n",
    "# Faire des prédictions sur les données d'entraînement\n",
    "train_pred = log_reg.predict_proba(train_final)[:, 1]\n",
    "\n",
    "# Calculer le score ROC AUC sur les données d'entraînement\n",
    "roc_auc = roc_auc_score(train_labels, train_pred)\n",
    "\n",
    "# Afficher le score ROC AUC\n",
    "print(f'ROC AUC Score: {roc_auc:.4f}')\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "log_reg_pred = log_reg.predict_proba(test_final)[:, 1]\n",
    "\n",
    "# Créer le DataFrame de soumission\n",
    "submit = app_test[['SK_ID_CURR']]\n",
    "submit['TARGET'] = log_reg_pred\n",
    "\n",
    "submit.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c2c450-e5a0-4033-9b03-f285c73c2d49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "736f2891-4329-4793-9279-a4e274a87c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.7277\n",
      "Prédictions:\n",
      "   SK_ID_CURR    TARGET\n",
      "0      342180  0.045878\n",
      "1      259636  0.079470\n",
      "2      305882  0.045878\n",
      "3      243264  0.037365\n",
      "4      264946  0.061666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# Charger les données\n",
    "app_train = pd.read_csv('data/application_train_split.csv')\n",
    "app_test = pd.read_csv('data/application_test_split.csv')\n",
    "\n",
    "# Convertir toutes les colonnes en numériques en utilisant LabelEncoder\n",
    "label_encoders = {}\n",
    "for col in app_train.columns:\n",
    "    if app_train[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        app_train[col] = le.fit_transform(app_train[col].astype(str))\n",
    "        if col in app_test.columns:\n",
    "            app_test[col] = le.transform(app_test[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Séparer les données d'entraînement et les labels\n",
    "if 'TARGET' in app_train:\n",
    "    train = app_train.drop(columns=['TARGET'])\n",
    "    train_labels = app_train['TARGET']\n",
    "else:\n",
    "    train = app_train.copy()\n",
    "    train_labels = None\n",
    "\n",
    "# Préparer les données de test sans l'identifiant\n",
    "test = app_test.drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "# S'assurer que les colonnes sont alignées avant l'imputation\n",
    "common_cols = train.columns.intersection(test.columns)\n",
    "train = train[common_cols]\n",
    "test = test[common_cols]\n",
    "\n",
    "# Imputer les valeurs manquantes avec la médiane\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "train = imputer.fit_transform(train)\n",
    "test = imputer.transform(test)\n",
    "\n",
    "# Créer le modèle d'Arbre de Décision avec des hyperparamètres\n",
    "decision_tree = DecisionTreeClassifier(max_depth=7, min_samples_split=10, min_samples_leaf=5)\n",
    "\n",
    "# Entraîner le modèle\n",
    "decision_tree.fit(train, train_labels)\n",
    "\n",
    "# Faire des prédictions sur les données d'entraînement\n",
    "train_pred = decision_tree.predict_proba(train)[:, 1]\n",
    "\n",
    "# Calculer le score ROC AUC sur les données d'entraînement\n",
    "roc_auc = roc_auc_score(train_labels, train_pred)\n",
    "\n",
    "# Afficher le score ROC AUC\n",
    "print(f'ROC AUC Score: {roc_auc:.4f}')\n",
    "\n",
    "# Extraire l'importance des caractéristiques\n",
    "feature_importance_values = decision_tree.feature_importances_\n",
    "feature_importances = pd.DataFrame({'feature': common_cols, 'importance': feature_importance_values})\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = decision_tree.predict_proba(test)[:, 1]\n",
    "\n",
    "# Créer le DataFrame de soumission\n",
    "submit = pd.DataFrame({'SK_ID_CURR': app_test['SK_ID_CURR'], 'TARGET': predictions})\n",
    "\n",
    "print(\"Prédictions:\")\n",
    "print(submit.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f90fe8-b379-4fb2-9f90-1e169a65c26f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "39a5bcdf-cab0-4821-94cb-cfe584d40f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.8230\n",
      "Prédictions:\n",
      "   SK_ID_CURR  TARGET\n",
      "0      342180     0.0\n",
      "1      259636     0.0\n",
      "2      305882     0.0\n",
      "3      243264     0.0\n",
      "4      264946     0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# Charger les données\n",
    "app_train = pd.read_csv('data/application_train_split.csv')\n",
    "app_test = pd.read_csv('data/application_test_split.csv')\n",
    "\n",
    "# Convertir toutes les colonnes en numériques en utilisant LabelEncoder\n",
    "label_encoders = {}\n",
    "for col in app_train.columns:\n",
    "    if app_train[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        app_train[col] = le.fit_transform(app_train[col].astype(str))\n",
    "        if col in app_test.columns:\n",
    "            app_test[col] = le.transform(app_test[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Séparer les données d'entraînement et les labels\n",
    "if 'TARGET' in app_train:\n",
    "    train = app_train.drop(columns=['TARGET'])\n",
    "    train_labels = app_train['TARGET']\n",
    "else:\n",
    "    train = app_train.copy()\n",
    "    train_labels = None\n",
    "\n",
    "# Préparer les données de test sans l'identifiant\n",
    "test = app_test.drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "# S'assurer que les colonnes sont alignées avant l'imputation\n",
    "common_cols = train.columns.intersection(test.columns)\n",
    "train = train[common_cols]\n",
    "test = test[common_cols]\n",
    "\n",
    "# Imputer les valeurs manquantes avec la médiane\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "train = imputer.fit_transform(train)\n",
    "test = imputer.transform(test)\n",
    "\n",
    "# Créer le modèle RandomForest\n",
    "random_forest = RandomForestClassifier(n_estimators=1, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Entraîner le modèle\n",
    "random_forest.fit(train, train_labels)\n",
    "\n",
    "# Faire des prédictions sur les données d'entraînement\n",
    "train_pred = random_forest.predict_proba(train)[:, 1]\n",
    "\n",
    "# Calculer le score ROC AUC sur les données d'entraînement\n",
    "roc_auc = roc_auc_score(train_labels, train_pred)\n",
    "\n",
    "# Afficher le score ROC AUC\n",
    "print(f'ROC AUC Score: {roc_auc:.4f}')\n",
    "\n",
    "# Extraire l'importance des caractéristiques\n",
    "feature_importance_values = random_forest.feature_importances_\n",
    "feature_importances = pd.DataFrame({'feature': common_cols, 'importance': feature_importance_values})\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = random_forest.predict_proba(test)[:, 1]\n",
    "\n",
    "# Créer le DataFrame de soumission\n",
    "submit = pd.DataFrame({'SK_ID_CURR': app_test['SK_ID_CURR'], 'TARGET': predictions})\n",
    "\n",
    "print(\"Prédictions:\")\n",
    "print(submit.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3280e2-9c4d-4a95-a881-29af62b8a4b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Fonction unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "f86fc626-f1e5-4404-8dd1-34e35c790219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores ROC AUC des modèles :\n",
      "                 Model  ROC AUC Score\n",
      "       DummyClassifier       0.852121\n",
      "    LogisticRegression       0.685603\n",
      "DecisionTreeClassifier       0.727685\n",
      "RandomForestClassifier       0.829548\n",
      "    CatBoostClassifier       0.768578\n",
      "    LightGBMClassifier       0.798777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "def process_and_predict(train_file, test_file):\n",
    "    # Configurer le logging pour ignorer les messages d'information de LightGBM\n",
    "    logging.getLogger('lightgbm').setLevel(logging.ERROR)\n",
    "    \n",
    "    # Rediriger stdout pour éviter les messages d'information de LightGBM\n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = open('/dev/null', 'w')  # Sur Unix/Linux/Mac\n",
    "    # sys.stdout = open(os.devnull, 'w')  # Sur Windows\n",
    "    \n",
    "    # Charger les données\n",
    "    app_train = pd.read_csv(train_file)\n",
    "    app_test = pd.read_csv(test_file)\n",
    "    \n",
    "    # Convertir toutes les colonnes en numériques en utilisant LabelEncoder\n",
    "    label_encoders = {}\n",
    "    for col in app_train.columns:\n",
    "        if app_train[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            app_train[col] = le.fit_transform(app_train[col].astype(str))\n",
    "            if col in app_test.columns:\n",
    "                app_test[col] = le.transform(app_test[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    # Séparer les données d'entraînement et les labels\n",
    "    if 'TARGET' in app_train:\n",
    "        train = app_train.drop(columns=['TARGET'])\n",
    "        train_labels = app_train['TARGET']\n",
    "    else:\n",
    "        raise ValueError(\"La colonne 'TARGET' n'existe pas dans les données d'entraînement.\")\n",
    "    \n",
    "    # Préparer les données de test sans l'identifiant\n",
    "    test = app_test.drop(columns=['SK_ID_CURR'])\n",
    "    \n",
    "    # S'assurer que les colonnes sont alignées avant l'imputation\n",
    "    common_cols = train.columns.intersection(test.columns)\n",
    "    train = train[common_cols]\n",
    "    test = test[common_cols]\n",
    "    \n",
    "    # Imputer les valeurs manquantes avec la médiane\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    train_numeric = imputer.fit_transform(train)\n",
    "    test_numeric = imputer.transform(test)\n",
    "    \n",
    "    # Normaliser les colonnes numériques\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_numeric = scaler.fit_transform(train_numeric)\n",
    "    test_numeric = scaler.transform(test_numeric)\n",
    "    \n",
    "    # Convertir les matrices numpy en DataFrames pandas\n",
    "    train_final = pd.DataFrame(train_numeric, columns=common_cols)\n",
    "    test_final = pd.DataFrame(test_numeric, columns=common_cols)\n",
    "    \n",
    "    # Créer et entraîner le DummyClassifier\n",
    "    dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "    dummy_clf.fit(train_final, train_labels)\n",
    "    dummy_predictions = dummy_clf.predict(test_final)\n",
    "    dummy_score = dummy_clf.score(train_final, train_labels)\n",
    "    \n",
    "    # Créer et entraîner le modèle LogisticRegression\n",
    "    log_reg = LogisticRegression(C=0.0001, max_iter=1000)\n",
    "    log_reg.fit(train_final, train_labels)\n",
    "    train_pred_log_reg = log_reg.predict_proba(train_final)[:, 1]\n",
    "    roc_auc_log_reg = roc_auc_score(train_labels, train_pred_log_reg)\n",
    "    \n",
    "    # Créer et entraîner le modèle DecisionTreeClassifier\n",
    "    decision_tree = DecisionTreeClassifier(max_depth=7, min_samples_split=10, min_samples_leaf=5)\n",
    "    decision_tree.fit(train_final, train_labels)\n",
    "    train_pred_tree = decision_tree.predict_proba(train_final)[:, 1]\n",
    "    roc_auc_tree = roc_auc_score(train_labels, train_pred_tree)\n",
    "    \n",
    "    # Créer et entraîner le modèle RandomForestClassifier\n",
    "    random_forest = RandomForestClassifier(n_estimators=1, verbose=1, n_jobs=-1)\n",
    "    random_forest.fit(train_final, train_labels)\n",
    "    train_pred_rf = random_forest.predict_proba(train_final)[:, 1]\n",
    "    roc_auc_rf = roc_auc_score(train_labels, train_pred_rf)\n",
    "    \n",
    "    # Créer et entraîner le modèle CatBoostClassifier\n",
    "    catboost_model = CatBoostClassifier(iterations=100, depth=7, learning_rate=0.1, loss_function='Logloss', verbose=0)\n",
    "    catboost_model.fit(train_final, train_labels)\n",
    "    train_pred_catboost = catboost_model.predict_proba(train_final)[:, 1]\n",
    "    roc_auc_catboost = roc_auc_score(train_labels, train_pred_catboost)\n",
    "    catboost_predictions = catboost_model.predict_proba(test_final)[:, 1]\n",
    "    \n",
    "    # Créer et entraîner le modèle LightGBMClassifier\n",
    "    lightgbm_model = lgb.LGBMClassifier(n_estimators=100, max_depth=7, learning_rate=0.1)\n",
    "    lightgbm_model.fit(train_final, train_labels)\n",
    "    train_pred_lightgbm = lightgbm_model.predict_proba(train_final)[:, 1]\n",
    "    roc_auc_lightgbm = roc_auc_score(train_labels, train_pred_lightgbm)\n",
    "    lightgbm_predictions = lightgbm_model.predict_proba(test_final)[:, 1]\n",
    "    \n",
    "    # Rétablir stdout\n",
    "    sys.stdout = original_stdout\n",
    "    \n",
    "    # Afficher les résultats dans un tableau lisible\n",
    "    results = {\n",
    "        'Model': ['DummyClassifier', 'LogisticRegression', 'DecisionTreeClassifier', 'RandomForestClassifier', 'CatBoostClassifier', 'LightGBMClassifier'],\n",
    "        'ROC AUC Score': [dummy_score, roc_auc_log_reg, roc_auc_tree, roc_auc_rf, roc_auc_catboost, roc_auc_lightgbm]\n",
    "    }\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    print(\"Scores ROC AUC des modèles :\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    return {\n",
    "        'DummyClassifier': dummy_predictions,\n",
    "        'LogisticRegression': log_reg.predict_proba(test_final)[:, 1],\n",
    "        'DecisionTreeClassifier': decision_tree.predict_proba(test_final)[:, 1],\n",
    "        'RandomForestClassifier': random_forest.predict_proba(test_final)[:, 1],\n",
    "        'CatBoostClassifier': catboost_predictions,\n",
    "        'LightGBMClassifier': lightgbm_predictions\n",
    "    }\n",
    "\n",
    "# Appel de la fonction avec les chemins des fichiers\n",
    "predictions = process_and_predict('data/application_train_split.csv', 'data/application_test_split.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aa68fa-883d-4539-9147-9e08c52d76df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Fonction unique avec CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "48e3b723-6652-4338-89b6-3b3c91cbec26",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[521], line 196\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDummyClassifier\u001b[39m\u001b[38;5;124m'\u001b[39m: dummy_predictions,\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogisticRegression\u001b[39m\u001b[38;5;124m'\u001b[39m: log_reg_grid\u001b[38;5;241m.\u001b[39mpredict_proba(test_final)[:, \u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLightGBMClassifier\u001b[39m\u001b[38;5;124m'\u001b[39m: lightgbm_predictions\n\u001b[1;32m    193\u001b[0m     }\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# Appel de la fonction avec les chemins des fichiers\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m predictions \u001b[38;5;241m=\u001b[39m process_and_predict(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/application_train_split.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/application_test_split.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[521], line 89\u001b[0m, in \u001b[0;36mprocess_and_predict\u001b[0;34m(train_file, test_file)\u001b[0m\n\u001b[1;32m     87\u001b[0m log_reg \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m)  \u001b[38;5;66;03m# Augmenté à 2000\u001b[39;00m\n\u001b[1;32m     88\u001b[0m log_reg_grid \u001b[38;5;241m=\u001b[39m GridSearchCV(log_reg, log_reg_params, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 89\u001b[0m log_reg_grid\u001b[38;5;241m.\u001b[39mfit(train_final, train_labels)\n\u001b[1;32m     90\u001b[0m log_reg_auc \u001b[38;5;241m=\u001b[39m roc_auc_score(train_labels, log_reg_grid\u001b[38;5;241m.\u001b[39mpredict_proba(train_final)[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     91\u001b[0m log_reg_time \u001b[38;5;241m=\u001b[39m measure_prediction_time(log_reg_grid, test_final)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1291\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1289\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1291\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, prefer\u001b[38;5;241m=\u001b[39mprefer)(\n\u001b[1;32m   1292\u001b[0m     path_func(\n\u001b[1;32m   1293\u001b[0m         X,\n\u001b[1;32m   1294\u001b[0m         y,\n\u001b[1;32m   1295\u001b[0m         pos_class\u001b[38;5;241m=\u001b[39mclass_,\n\u001b[1;32m   1296\u001b[0m         Cs\u001b[38;5;241m=\u001b[39m[C_],\n\u001b[1;32m   1297\u001b[0m         l1_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_ratio,\n\u001b[1;32m   1298\u001b[0m         fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept,\n\u001b[1;32m   1299\u001b[0m         tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[1;32m   1300\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m   1301\u001b[0m         solver\u001b[38;5;241m=\u001b[39msolver,\n\u001b[1;32m   1302\u001b[0m         multi_class\u001b[38;5;241m=\u001b[39mmulti_class,\n\u001b[1;32m   1303\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[1;32m   1304\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m   1305\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1306\u001b[0m         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[1;32m   1307\u001b[0m         coef\u001b[38;5;241m=\u001b[39mwarm_start_coef_,\n\u001b[1;32m   1308\u001b[0m         penalty\u001b[38;5;241m=\u001b[39mpenalty,\n\u001b[1;32m   1309\u001b[0m         max_squared_sum\u001b[38;5;241m=\u001b[39mmax_squared_sum,\n\u001b[1;32m   1310\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1311\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[1;32m   1312\u001b[0m     )\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m class_, warm_start_coef_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(classes_, warm_start_coef)\n\u001b[1;32m   1314\u001b[0m )\n\u001b[1;32m   1316\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:450\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    446\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C\n\u001b[1;32m    447\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[1;32m    448\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[1;32m    449\u001b[0m ]\n\u001b[0;32m--> 450\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m optimize\u001b[38;5;241m.\u001b[39mminimize(\n\u001b[1;32m    451\u001b[0m     func,\n\u001b[1;32m    452\u001b[0m     w0,\n\u001b[1;32m    453\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL-BFGS-B\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    454\u001b[0m     jac\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    455\u001b[0m     args\u001b[38;5;241m=\u001b[39m(X, target, sample_weight, l2_reg_strength, n_threads),\n\u001b[1;32m    456\u001b[0m     options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miprint\u001b[39m\u001b[38;5;124m\"\u001b[39m: iprint, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgtol\u001b[39m\u001b[38;5;124m\"\u001b[39m: tol, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_iter},\n\u001b[1;32m    457\u001b[0m )\n\u001b[1;32m    458\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[1;32m    459\u001b[0m     solver,\n\u001b[1;32m    460\u001b[0m     opt_res,\n\u001b[1;32m    461\u001b[0m     max_iter,\n\u001b[1;32m    462\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[1;32m    463\u001b[0m )\n\u001b[1;32m    464\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/optimize/_minimize.py:710\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    707\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    708\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m    711\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    714\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py:365\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    359\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 365\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m func_and_grad(x)\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    368\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl()\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/optimize/_optimize.py:77\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_if_needed(x, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/optimize/_optimize.py:71\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 71\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfun(x, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:291\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    289\u001b[0m     grad[:n_features] \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m grad_pointwise \u001b[38;5;241m+\u001b[39m l2_reg_strength \u001b[38;5;241m*\u001b[39m weights\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept:\n\u001b[0;32m--> 291\u001b[0m         grad[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m grad_pointwise\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m     grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((n_classes, n_dof), dtype\u001b[38;5;241m=\u001b[39mweights\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:47\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prod\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     52\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "\n",
    "def measure_prediction_time(model, X, n_predictions=1000):\n",
    "    \"\"\"Mesurer le temps de prédiction moyen sur n_predictions échantillons.\"\"\"\n",
    "    start_time = time.time()\n",
    "    for _ in range(n_predictions):\n",
    "        _ = model.predict_proba(X)[:, 1]\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    return \"{:.2f} s\".format(elapsed_time)\n",
    "\n",
    "def process_and_predict(train_file, test_file):\n",
    "    # Configurer le logging pour ignorer les messages d'information de LightGBM\n",
    "    logging.getLogger('lightgbm').setLevel(logging.ERROR)\n",
    "    \n",
    "    # Rediriger stdout pour éviter les messages d'information de LightGBM\n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = open('/dev/null', 'w')  # Sur Unix/Linux/Mac\n",
    "    \n",
    "    # Charger les données\n",
    "    app_train = pd.read_csv(train_file)\n",
    "    app_test = pd.read_csv(test_file)\n",
    "    \n",
    "    # Convertir toutes les colonnes en numériques en utilisant LabelEncoder\n",
    "    label_encoders = {}\n",
    "    for col in app_train.columns:\n",
    "        if app_train[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            app_train[col] = le.fit_transform(app_train[col].astype(str))\n",
    "            if col in app_test.columns:\n",
    "                app_test[col] = le.transform(app_test[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    # Séparer les données d'entraînement et les labels\n",
    "    if 'TARGET' in app_train:\n",
    "        train = app_train.drop(columns=['TARGET'])\n",
    "        train_labels = app_train['TARGET']\n",
    "    else:\n",
    "        raise ValueError(\"La colonne 'TARGET' n'existe pas dans les données d'entraînement.\")\n",
    "    \n",
    "    # Préparer les données de test sans l'identifiant\n",
    "    test = app_test.drop(columns=['SK_ID_CURR'])\n",
    "    \n",
    "    # S'assurer que les colonnes sont alignées avant l'imputation\n",
    "    common_cols = train.columns.intersection(test.columns)\n",
    "    train = train[common_cols]\n",
    "    test = test[common_cols]\n",
    "    \n",
    "    # Imputer les valeurs manquantes avec la médiane\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    train_numeric = imputer.fit_transform(train)\n",
    "    test_numeric = imputer.transform(test)\n",
    "    \n",
    "    # Normaliser les colonnes numériques\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_numeric = scaler.fit_transform(train_numeric)\n",
    "    test_numeric = scaler.transform(test_numeric)\n",
    "    \n",
    "    # Convertir les matrices numpy en DataFrames pandas\n",
    "    train_final = pd.DataFrame(train_numeric, columns=common_cols)\n",
    "    test_final = pd.DataFrame(test_numeric, columns=common_cols)\n",
    "    \n",
    "    # Créer et entraîner le DummyClassifier\n",
    "    dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "    dummy_clf.fit(train_final, train_labels)\n",
    "    dummy_predictions = dummy_clf.predict_proba(test_final)[:, 1]\n",
    "    dummy_auc = roc_auc_score(train_labels, dummy_clf.predict_proba(train_final)[:, 1])\n",
    "    dummy_time = measure_prediction_time(dummy_clf, test_final)\n",
    "    \n",
    "    # Définir les paramètres pour GridSearchCV pour LogisticRegression\n",
    "    log_reg_params = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "    log_reg = LogisticRegression(max_iter=2000)  # Augmenté à 2000\n",
    "    log_reg_grid = GridSearchCV(log_reg, log_reg_params, cv=5, scoring='roc_auc')\n",
    "    log_reg_grid.fit(train_final, train_labels)\n",
    "    log_reg_auc = roc_auc_score(train_labels, log_reg_grid.predict_proba(train_final)[:, 1])\n",
    "    log_reg_time = measure_prediction_time(log_reg_grid, test_final)\n",
    "    \n",
    "    # Définir les paramètres pour GridSearchCV pour DecisionTreeClassifier\n",
    "    tree_params = {'max_depth': [5, 7, 10], 'min_samples_split': [10, 20, 50]}\n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    tree_grid = GridSearchCV(decision_tree, tree_params, cv=5, scoring='roc_auc')\n",
    "    tree_grid.fit(train_final, train_labels)\n",
    "    tree_auc = roc_auc_score(train_labels, tree_grid.predict_proba(train_final)[:, 1])\n",
    "    tree_time = measure_prediction_time(tree_grid, test_final)\n",
    "    \n",
    "    # Définir les paramètres pour GridSearchCV pour RandomForestClassifier\n",
    "    rf_params = {'n_estimators': [10, 50, 100], 'max_depth': [5, 7, 10]}\n",
    "    random_forest = RandomForestClassifier(n_jobs=-1)\n",
    "    rf_grid = GridSearchCV(random_forest, rf_params, cv=5, scoring='roc_auc')\n",
    "    rf_grid.fit(train_final, train_labels)\n",
    "    rf_auc = roc_auc_score(train_labels, rf_grid.predict_proba(train_final)[:, 1])\n",
    "    rf_time = measure_prediction_time(rf_grid, test_final)\n",
    "    \n",
    "    # Définir les paramètres pour GridSearchCV pour CatBoostClassifier\n",
    "    catboost_params = {'depth': [1,2, 3,4, 5], 'learning_rate': [0.01, 0.1, 0.3]}\n",
    "    catboost_model = CatBoostClassifier(iterations=100, loss_function='Logloss', verbose=0)\n",
    "    catboost_grid = GridSearchCV(catboost_model, catboost_params, cv=5, scoring='roc_auc')\n",
    "    catboost_grid.fit(train_final, train_labels)\n",
    "    catboost_auc = roc_auc_score(train_labels, catboost_grid.predict_proba(train_final)[:, 1])\n",
    "    catboost_predictions = catboost_grid.predict_proba(test_final)[:, 1]\n",
    "    catboost_time = measure_prediction_time(catboost_grid, test_final)\n",
    "    \n",
    "    # Définir les paramètres pour GridSearchCV pour LightGBMClassifier\n",
    "    lightgbm_params = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'max_depth': [1,2, 3,4, 5],\n",
    "        'num_leaves': [2**6 - 1, 2**7 - 1, 2**8 - 1]  # Ajusté pour respecter la condition\n",
    "    }\n",
    "    lightgbm_model = lgb.LGBMClassifier()\n",
    "    lightgbm_grid = GridSearchCV(lightgbm_model, lightgbm_params, cv=5, scoring='roc_auc')\n",
    "    lightgbm_grid.fit(train_final, train_labels)\n",
    "    lightgbm_auc = roc_auc_score(train_labels, lightgbm_grid.predict_proba(train_final)[:, 1])\n",
    "    lightgbm_predictions = lightgbm_grid.predict_proba(test_final)[:, 1]\n",
    "    lightgbm_time = measure_prediction_time(lightgbm_grid, test_final)\n",
    "    \n",
    "    # Rétablir stdout\n",
    "    sys.stdout = original_stdout\n",
    "\n",
    "    # Afficher les meilleurs hyperparamètres pour chaque modèle\n",
    "    best_params = {\n",
    "        'LogisticRegression': log_reg_grid.best_params_,\n",
    "        'DecisionTreeClassifier': tree_grid.best_params_,\n",
    "        'RandomForestClassifier': rf_grid.best_params_,\n",
    "        'CatBoostClassifier': catboost_grid.best_params_,\n",
    "        'LightGBMClassifier': lightgbm_grid.best_params_\n",
    "    }\n",
    "    \n",
    "    print(\"Meilleurs hyperparamètres pour chaque modèle :\")\n",
    "    for model_name, params in best_params.items():\n",
    "        print(f\"{model_name}: {params}\")\n",
    "    \n",
    "    # Calcul des métriques pour chaque modèle\n",
    "    models = {\n",
    "        'DummyClassifier': dummy_clf,\n",
    "        'LogisticRegression': log_reg_grid,\n",
    "        'DecisionTreeClassifier': tree_grid,\n",
    "        'RandomForestClassifier': rf_grid,\n",
    "        'CatBoostClassifier': catboost_grid,\n",
    "        'LightGBMClassifier': lightgbm_grid\n",
    "    }\n",
    "\n",
    "    metrics = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        train_pred = model.predict(train_final)\n",
    "        auc_score = roc_auc_score(train_labels, model.predict_proba(train_final)[:, 1])\n",
    "        precision = precision_score(train_labels, train_pred, zero_division=0)\n",
    "        recall = recall_score(train_labels, train_pred, zero_division=0)\n",
    "        f1 = f1_score(train_labels, train_pred, zero_division=0)\n",
    "        cm = confusion_matrix(train_labels, train_pred)\n",
    "        cm_str = f\"TN: {cm[0, 0]}, FP: {cm[0, 1]}, FN: {cm[1, 0]}, TP: {cm[1, 1]}\"\n",
    "        time_metric = measure_prediction_time(model, test_final)\n",
    "        metrics.append([\n",
    "            name,\n",
    "            f\"{auc_score:.5f}\",\n",
    "            f\"{precision:.5f}\",\n",
    "            f\"{recall:.5f}\",\n",
    "            f\"{f1:.5f}\",\n",
    "            cm_str,\n",
    "            time_metric\n",
    "        ])\n",
    "    \n",
    "    # Affichage des résultats\n",
    "    headers = ['Model', 'ROC AUC', 'Precision', 'Recall', 'F1 Score', 'Confusion Matrix', 'Time for 1000 Predictions (s)']\n",
    "    results_table = tabulate(metrics, headers, tablefmt='grid')\n",
    "    \n",
    "    print(\"Résultats des modèles :\")\n",
    "    print(results_table)\n",
    "    \n",
    "    return {\n",
    "        'DummyClassifier': dummy_predictions,\n",
    "        'LogisticRegression': log_reg_grid.predict_proba(test_final)[:, 1],\n",
    "        'DecisionTreeClassifier': tree_grid.predict_proba(test_final)[:, 1],\n",
    "        'RandomForestClassifier': rf_grid.predict_proba(test_final)[:, 1],\n",
    "        'CatBoostClassifier': catboost_predictions,\n",
    "        'LightGBMClassifier': lightgbm_predictions\n",
    "    }\n",
    "\n",
    "# Appel de la fonction avec les chemins des fichiers\n",
    "predictions = process_and_predict('data/application_train_split.csv', 'data/application_test_split.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b470ec-91df-418c-ab20-8a835765cceb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Ponderation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e811a48e-80b2-43cd-be0c-35e32bf9a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "\n",
    "def measure_prediction_time(model, X, n_predictions=1000):\n",
    "    \"\"\"Mesurer le temps de prédiction moyen sur n_predictions échantillons.\"\"\"\n",
    "    start_time = time.time()\n",
    "    for _ in range(n_predictions):\n",
    "        _ = model.predict_proba(X)[:, 1]\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    return \"{:.2f} s\".format(elapsed_time)\n",
    "\n",
    "def process_and_predict(train_file, test_file):\n",
    "    # Configurer le logging pour ignorer les messages d'information de LightGBM\n",
    "    logging.getLogger('lightgbm').setLevel(logging.ERROR)\n",
    "    \n",
    "    # Rediriger stdout pour éviter les messages d'information de LightGBM\n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = open('/dev/null', 'w')  # Sur Unix/Linux/Mac\n",
    "    \n",
    "    # Charger les données\n",
    "    app_train = pd.read_csv(train_file)\n",
    "    app_test = pd.read_csv(test_file)\n",
    "    \n",
    "    # Convertir toutes les colonnes en numériques en utilisant LabelEncoder\n",
    "    label_encoders = {}\n",
    "    for col in app_train.columns:\n",
    "        if app_train[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            app_train[col] = le.fit_transform(app_train[col].astype(str))\n",
    "            if col in app_test.columns:\n",
    "                app_test[col] = le.transform(app_test[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    # Séparer les données d'entraînement et les labels\n",
    "    if 'TARGET' in app_train:\n",
    "        train = app_train.drop(columns=['TARGET'])\n",
    "        train_labels = app_train['TARGET']\n",
    "    else:\n",
    "        raise ValueError(\"La colonne 'TARGET' n'existe pas dans les données d'entraînement.\")\n",
    "    \n",
    "    # Préparer les données de test sans l'identifiant\n",
    "    test = app_test.drop(columns=['SK_ID_CURR'])\n",
    "    \n",
    "    # S'assurer que les colonnes sont alignées avant l'imputation\n",
    "    common_cols = train.columns.intersection(test.columns)\n",
    "    train = train[common_cols]\n",
    "    test = test[common_cols]\n",
    "    \n",
    "    # Imputer les valeurs manquantes avec la médiane\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    train_numeric = imputer.fit_transform(train)\n",
    "    test_numeric = imputer.transform(test)\n",
    "    \n",
    "    # Normaliser les colonnes numériques\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_numeric = scaler.fit_transform(train_numeric)\n",
    "    test_numeric = scaler.transform(test_numeric)\n",
    "    \n",
    "    # Convertir les matrices numpy en DataFrames pandas\n",
    "    train_final = pd.DataFrame(train_numeric, columns=common_cols)\n",
    "    test_final = pd.DataFrame(test_numeric, columns=common_cols)\n",
    "    \n",
    "    # Créer et entraîner le DummyClassifier\n",
    "    dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "    dummy_clf.fit(train_final, train_labels)\n",
    "    dummy_predictions = dummy_clf.predict_proba(test_final)[:, 1]\n",
    "    dummy_auc = roc_auc_score(train_labels, dummy_clf.predict_proba(train_final)[:, 1])\n",
    "    dummy_time = measure_prediction_time(dummy_clf, test_final)\n",
    "    \n",
    "    # Définir les paramètres pour GridSearchCV pour LogisticRegression avec pondération des classes\n",
    "    log_reg_params = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "    log_reg = LogisticRegression(max_iter=3000, class_weight='balanced')  # Ajout de class_weight='balanced'\n",
    "    log_reg_grid = GridSearchCV(log_reg, log_reg_params, cv=5, scoring='roc_auc')\n",
    "    log_reg_grid.fit(train_final, train_labels)\n",
    "    log_reg_auc = roc_auc_score(train_labels, log_reg_grid.predict_proba(train_final)[:, 1])\n",
    "    log_reg_time = measure_prediction_time(log_reg_grid, test_final)\n",
    "    \n",
    "    # Définir les paramètres pour GridSearchCV pour DecisionTreeClassifier avec pondération des classes\n",
    "    tree_params = {'max_depth': [5, 7, 10], 'min_samples_split': [10, 20, 50]}\n",
    "    decision_tree = DecisionTreeClassifier(class_weight='balanced')  # Ajout de class_weight='balanced'\n",
    "    tree_grid = GridSearchCV(decision_tree, tree_params, cv=5, scoring='roc_auc')\n",
    "    tree_grid.fit(train_final, train_labels)\n",
    "    tree_auc = roc_auc_score(train_labels, tree_grid.predict_proba(train_final)[:, 1])\n",
    "    tree_time = measure_prediction_time(tree_grid, test_final)\n",
    "    \n",
    "    # Définir les paramètres pour GridSearchCV pour RandomForestClassifier\n",
    "    rf_params = {'n_estimators': [10, 50, 100], 'max_depth': [2,3,4,5, 7,10,15]}\n",
    "    random_forest = RandomForestClassifier(n_jobs=-1,class_weight='balanced')\n",
    "    rf_grid = GridSearchCV(random_forest, rf_params, cv=5, scoring='roc_auc')\n",
    "    rf_grid.fit(train_final, train_labels)\n",
    "    rf_auc = roc_auc_score(train_labels, rf_grid.predict_proba(train_final)[:, 1])\n",
    "    rf_time = measure_prediction_time(rf_grid, test_final)\n",
    "    \n",
    "    # Définir les paramètres pour GridSearchCV pour CatBoostClassifier\n",
    "    catboost_params = {'depth': [1,2,3,4,5], 'learning_rate': [0.01, 0.1, 0.3]}\n",
    "    catboost_model = CatBoostClassifier(iterations=100, loss_function='Logloss', verbose=0)\n",
    "    catboost_grid = GridSearchCV(catboost_model, catboost_params, cv=5, scoring='roc_auc')\n",
    "    catboost_grid.fit(train_final, train_labels)\n",
    "    catboost_auc = roc_auc_score(train_labels, catboost_grid.predict_proba(train_final)[:, 1])\n",
    "    catboost_predictions = catboost_grid.predict_proba(test_final)[:, 1]\n",
    "    catboost_time = measure_prediction_time(catboost_grid, test_final)\n",
    "    \n",
    "    # Définir les paramètres pour GridSearchCV pour LightGBMClassifier\n",
    "    lightgbm_params = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'max_depth': [1,2,3,4,5],\n",
    "        'num_leaves': [2**6 - 1, 2**7 - 1, 2**8 - 1]  # Ajusté pour respecter la condition\n",
    "    }\n",
    "    lightgbm_model = lgb.LGBMClassifier()\n",
    "    lightgbm_grid = GridSearchCV(lightgbm_model, lightgbm_params, cv=5, scoring='roc_auc')\n",
    "    lightgbm_grid.fit(train_final, train_labels)\n",
    "    lightgbm_auc = roc_auc_score(train_labels, lightgbm_grid.predict_proba(train_final)[:, 1])\n",
    "    lightgbm_predictions = lightgbm_grid.predict_proba(test_final)[:, 1]\n",
    "    lightgbm_time = measure_prediction_time(lightgbm_grid, test_final)\n",
    "    \n",
    "    # Rétablir stdout\n",
    "    sys.stdout = original_stdout\n",
    "\n",
    "    # Afficher les meilleurs hyperparamètres pour chaque modèle\n",
    "    best_params = {\n",
    "        'LogisticRegression': log_reg_grid.best_params_,\n",
    "        'DecisionTreeClassifier': tree_grid.best_params_,\n",
    "        'RandomForestClassifier': rf_grid.best_params_,\n",
    "        'CatBoostClassifier': catboost_grid.best_params_,\n",
    "        'LightGBMClassifier': lightgbm_grid.best_params_\n",
    "    }\n",
    "    \n",
    "    print(\"Meilleurs hyperparamètres pour chaque modèle :\")\n",
    "    for model_name, params in best_params.items():\n",
    "        print(f\"{model_name}: {params}\")\n",
    "    \n",
    "    # Calcul des métriques pour chaque modèle\n",
    "    models = {\n",
    "        'DummyClassifier': dummy_clf,\n",
    "        'LogisticRegression': log_reg_grid,\n",
    "        'DecisionTreeClassifier': tree_grid,\n",
    "        'RandomForestClassifier': rf_grid,\n",
    "        'CatBoostClassifier': catboost_grid,\n",
    "        'LightGBMClassifier': lightgbm_grid\n",
    "    }\n",
    "\n",
    "    metrics = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        train_pred = model.predict(train_final)\n",
    "        auc_score = roc_auc_score(train_labels, model.predict_proba(train_final)[:, 1])\n",
    "        precision = precision_score(train_labels, train_pred, zero_division=0)\n",
    "        recall = recall_score(train_labels, train_pred, zero_division=0)\n",
    "        f1 = f1_score(train_labels, train_pred, zero_division=0)\n",
    "        cm = confusion_matrix(train_labels, train_pred)\n",
    "        cm_str = f\"TN: {cm[0, 0]}, FP: {cm[0, 1]}, FN: {cm[1, 0]}, TP: {cm[1, 1]}\"\n",
    "        time_metric = measure_prediction_time(model, test_final)\n",
    "        metrics.append([\n",
    "            name,\n",
    "            f\"{auc_score:.5f}\",\n",
    "            f\"{precision:.5f}\",\n",
    "            f\"{recall:.5f}\",\n",
    "            f\"{f1:.5f}\",\n",
    "            cm_str,\n",
    "            time_metric\n",
    "        ])\n",
    "    \n",
    "    # Affichage des résultats\n",
    "    headers = ['Model', 'ROC AUC', 'Precision', 'Recall', 'F1 Score', 'Confusion Matrix', 'Time for 1000 Predictions (s)']\n",
    "    results_table = tabulate(metrics, headers, tablefmt='grid')\n",
    "    \n",
    "    print(\"Résultats des modèles :\")\n",
    "    print(results_table)\n",
    "    \n",
    "    return {\n",
    "        'DummyClassifier': dummy_predictions,\n",
    "        'LogisticRegression': log_reg_grid.predict_proba(test_final)[:, 1],\n",
    "        'DecisionTreeClassifier': tree_grid.predict_proba(test_final)[:, 1],\n",
    "        'RandomForestClassifier': rf_grid.predict_proba(test_final)[:, 1],\n",
    "        'CatBoostClassifier': catboost_predictions,\n",
    "        'LightGBMClassifier': lightgbm_predictions\n",
    "    }\n",
    "\n",
    "# Appel de la fonction avec les chemins des fichiers\n",
    "predictions = process_and_predict('data/application_train_split.csv', 'data/application_test_split.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f7a7f-1e1e-4415-8e05-201a16c4d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "\n",
    "def measure_prediction_time(model, X, n_predictions=1000):\n",
    "    \"\"\"Mesurer le temps de prédiction moyen sur n_predictions échantillons.\"\"\"\n",
    "    start_time = time.time()\n",
    "    for _ in range(n_predictions):\n",
    "        _ = model.predict_proba(X)[:, 1]\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    return \"{:.2f}\".format(elapsed_time)\n",
    "\n",
    "def calculate_class_weights(labels):\n",
    "    \"\"\"Calculer les poids des classes basés sur la distribution des labels.\"\"\"\n",
    "    class_counts = labels.value_counts().to_dict()\n",
    "    total = sum(class_counts.values())\n",
    "    class_weights = {cls: total / (len(class_counts) * count) for cls, count in class_counts.items()}\n",
    "    return class_weights\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Évaluer les performances d'un modèle sur les ensembles d'entraînement et de test.\"\"\"\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    train_proba = model.predict_proba(X_train)[:, 1]\n",
    "    test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    metrics = {\n",
    "        'train_auc': roc_auc_score(y_train, train_proba),\n",
    "        'test_auc': roc_auc_score(y_test, test_proba),\n",
    "        'train_precision': precision_score(y_train, train_pred, zero_division=0),\n",
    "        'test_precision': precision_score(y_test, test_pred, zero_division=0),\n",
    "        'train_recall': recall_score(y_train, train_pred, zero_division=0),\n",
    "        'test_recall': recall_score(y_test, test_pred, zero_division=0),\n",
    "        'train_f1': f1_score(y_train, train_pred, zero_division=0),\n",
    "        'test_f1': f1_score(y_test, test_pred, zero_division=0),\n",
    "        'train_cm': confusion_matrix(y_train, train_pred),\n",
    "        'test_cm': confusion_matrix(y_test, test_pred)\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def process_and_predict(train_file, test_file):\n",
    "    # Configurer le logging pour ignorer les messages d'information de LightGBM\n",
    "    logging.getLogger('lightgbm').setLevel(logging.ERROR)\n",
    "    \n",
    "    # Rediriger stdout pour éviter les messages d'information de LightGBM\n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = open('/dev/null', 'w')  # Sur Unix/Linux/Mac\n",
    "    \n",
    "    # Charger les données\n",
    "    app_train = pd.read_csv(train_file)\n",
    "    app_test = pd.read_csv(test_file)\n",
    "    \n",
    "    # Convertir toutes les colonnes en numériques en utilisant LabelEncoder\n",
    "    label_encoders = {}\n",
    "    for col in app_train.columns:\n",
    "        if app_train[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            app_train[col] = le.fit_transform(app_train[col].astype(str))\n",
    "            if col in app_test.columns:\n",
    "                app_test[col] = le.transform(app_test[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    # Séparer les données d'entraînement et les labels\n",
    "    if 'TARGET' in app_train:\n",
    "        train = app_train.drop(columns=['TARGET'])\n",
    "        train_labels = app_train['TARGET']\n",
    "    else:\n",
    "        raise ValueError(\"La colonne 'TARGET' n'existe pas dans les données d'entraînement.\")\n",
    "    \n",
    "    # Préparer les données de test sans l'identifiant\n",
    "    test = app_test.drop(columns=['SK_ID_CURR'])\n",
    "    \n",
    "    # S'assurer que les colonnes sont alignées avant l'imputation\n",
    "    common_cols = train.columns.intersection(test.columns)\n",
    "    train = train[common_cols]\n",
    "    test = test[common_cols]\n",
    "    \n",
    "    # Imputer les valeurs manquantes avec la médiane\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    train_numeric = imputer.fit_transform(train)\n",
    "    test_numeric = imputer.transform(test)\n",
    "    \n",
    "    # Normaliser les colonnes numériques\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_numeric = scaler.fit_transform(train_numeric)\n",
    "    test_numeric = scaler.transform(test_numeric)\n",
    "    \n",
    "    # Convertir les matrices numpy en DataFrames pandas\n",
    "    train_final = pd.DataFrame(train_numeric, columns=common_cols)\n",
    "    test_final = pd.DataFrame(test_numeric, columns=common_cols)\n",
    "    \n",
    "    # Créer et entraîner les modèles\n",
    "    models = {}\n",
    "    \n",
    "    # DummyClassifier\n",
    "    dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "    dummy_clf.fit(train_final, train_labels)\n",
    "    models['DummyClassifier'] = dummy_clf\n",
    "\n",
    "    # LogisticRegression\n",
    "    log_reg_params = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "    log_reg = LogisticRegression(max_iter=3000, class_weight='balanced')\n",
    "    log_reg_grid = GridSearchCV(log_reg, log_reg_params, cv=5, scoring='roc_auc')\n",
    "    log_reg_grid.fit(train_final, train_labels)\n",
    "    models['LogisticRegression'] = log_reg_grid\n",
    "    \n",
    "    # DecisionTreeClassifier\n",
    "    tree_params = {'max_depth': [5,6, 7,8, 10], 'min_samples_split': [10, 20, 50]}\n",
    "    decision_tree = DecisionTreeClassifier(class_weight='balanced')\n",
    "    tree_grid = GridSearchCV(decision_tree, tree_params, cv=5, scoring='roc_auc')\n",
    "    tree_grid.fit(train_final, train_labels)\n",
    "    models['DecisionTreeClassifier'] = tree_grid\n",
    "    \n",
    "    # RandomForestClassifier\n",
    "    rf_params = {'n_estimators': [10, 50, 100], 'max_depth': [2, 3, 4, 5,6, 7,8, 10]}\n",
    "    random_forest = RandomForestClassifier(n_jobs=-1, class_weight='balanced')\n",
    "    rf_grid = GridSearchCV(random_forest, rf_params, cv=5, scoring='roc_auc')\n",
    "    rf_grid.fit(train_final, train_labels)\n",
    "    models['RandomForestClassifier'] = rf_grid\n",
    "    \n",
    "    # CatBoostClassifier\n",
    "    class_weights = calculate_class_weights(train_labels)\n",
    "    catboost_params = {'depth': [1, 2, 3, 4, 5], 'learning_rate': [0.01, 0.1,0.2, 0.3]}\n",
    "    catboost_model = CatBoostClassifier(iterations=100, loss_function='Logloss', class_weights=class_weights, verbose=0)\n",
    "    catboost_grid = GridSearchCV(catboost_model, catboost_params, cv=5, scoring='roc_auc')\n",
    "    catboost_grid.fit(train_final, train_labels)\n",
    "    models['CatBoostClassifier'] = catboost_grid\n",
    "    \n",
    "    # LightGBMClassifier\n",
    "    lightgbm_params = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1,0.2, 0.3],\n",
    "        'max_depth': [1, 2, 3, 4, 5],\n",
    "        'num_leaves': [2**6 - 1, 2**7 - 1, 2**8 - 1]\n",
    "    }\n",
    "    lightgbm_model = lgb.LGBMClassifier(class_weight=class_weights)\n",
    "    lightgbm_grid = GridSearchCV(lightgbm_model, lightgbm_params, cv=5, scoring='roc_auc')\n",
    "    lightgbm_grid.fit(train_final, train_labels)\n",
    "    models['LightGBMClassifier'] = lightgbm_grid\n",
    "    \n",
    "    # Rétablir stdout\n",
    "    sys.stdout = original_stdout\n",
    "\n",
    "    # Afficher les meilleurs hyperparamètres pour chaque modèle\n",
    "    best_params = {name: model.best_params_ if hasattr(model, 'best_params_') else {} for name, model in models.items()}\n",
    "    \n",
    "    print(\"Meilleurs hyperparamètres pour chaque modèle :\")\n",
    "    for model_name, params in best_params.items():\n",
    "        print(f\"{model_name}: {params}\")\n",
    "    \n",
    "    # Préparer les métriques pour les données d'entraînement et de test\n",
    "    metrics_train = []\n",
    "    metrics_test = []\n",
    "\n",
    "    catboost_predictions = None\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        metrics = evaluate_model(model, train_final, train_labels, test_final, app_test['TARGET'])\n",
    "        train_cm = metrics['train_cm']\n",
    "        test_cm = metrics['test_cm']\n",
    "        metrics_train.append([\n",
    "            name,\n",
    "            f\"{metrics['train_auc']:.5f}\",\n",
    "            f\"{metrics['train_precision']:.5f}\",\n",
    "            f\"{metrics['train_recall']:.5f}\",\n",
    "            f\"{metrics['train_f1']:.5f}\",\n",
    "            f\"{train_cm[0,0]} | {train_cm[0,1]}\\n{train_cm[1,0]} | {train_cm[1,1]}\",\n",
    "            measure_prediction_time(model, test_final)\n",
    "        ])\n",
    "        metrics_test.append([\n",
    "            name,\n",
    "            f\"{metrics['test_auc']:.5f}\",\n",
    "            f\"{metrics['test_precision']:.5f}\",\n",
    "            f\"{metrics['test_recall']:.5f}\",\n",
    "            f\"{metrics['test_f1']:.5f}\",\n",
    "            f\"{test_cm[0,0]} | {test_cm[0,1]}\\n{test_cm[1,0]} | {test_cm[1,1]}\",\n",
    "            measure_prediction_time(model, test_final)\n",
    "        ])\n",
    "        \n",
    "        # Spécial pour CatBoostClassifier\n",
    "        if name == 'CatBoostClassifier':\n",
    "            catboost_predictions = model.predict_proba(test_final)[:, 1]\n",
    "    \n",
    "    # Affichage des résultats pour les données d'entraînement\n",
    "    headers_train = ['Model', 'AUC', 'Precision', 'Recall', 'F1-Score', 'Confusion Matrix', 'Time (1000 estimations)']\n",
    "    results_table_train = tabulate(metrics_train, headers_train, tablefmt='pipe')\n",
    "    \n",
    "    print(\"\\nMétriques pour les données d'entraînement :\")\n",
    "    print(results_table_train)\n",
    "    \n",
    "    # Affichage des résultats pour les données de test\n",
    "    headers_test = ['Model', 'AUC', 'Precision', 'Recall', 'F1-Score', 'Confusion Matrix', 'Time (1000 estimations)']\n",
    "    results_table_test = tabulate(metrics_test, headers_test, tablefmt='pipe')\n",
    "    \n",
    "    print(\"\\nMétriques pour les données de test :\")\n",
    "    print(results_table_test)\n",
    "    \n",
    "    return best_params, metrics_test, catboost_predictions\n",
    "\n",
    "# Appel de la fonction avec les chemins des fichiers\n",
    "predictions = process_and_predict('data/application_train_split.csv', 'data/application_test_split.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5d45dd-333a-4958-b7e3-a9e3def08494",
   "metadata": {},
   "source": [
    "# Separation des fonctions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4d6dcf-6284-42f2-ac5f-82d5ac1bbbab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "id": "f0b84957-1d26-41d7-a4fe-3c9002c33b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def clean_data(train_file, test_file):\n",
    "    \"\"\"Nettoyer et préparer les données pour l'entraînement et le test.\"\"\"\n",
    "    print(\"Début du nettoyage des données...\")\n",
    "    \n",
    "    # Charger les données\n",
    "    app_train = pd.read_csv(train_file)\n",
    "    app_test = pd.read_csv(test_file)\n",
    "    \n",
    "    # Convertir toutes les colonnes en numériques en utilisant LabelEncoder\n",
    "    label_encoders = {}\n",
    "    for col in app_train.columns:\n",
    "        if app_train[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            app_train[col] = le.fit_transform(app_train[col].astype(str))\n",
    "            if col in app_test.columns:\n",
    "                app_test[col] = le.transform(app_test[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    # Séparer les données d'entraînement et les labels\n",
    "    if 'TARGET' in app_train:\n",
    "        train = app_train.drop(columns=['TARGET'])\n",
    "        train_labels = app_train['TARGET']\n",
    "    else:\n",
    "        raise ValueError(\"La colonne 'TARGET' n'existe pas dans les données d'entraînement.\")\n",
    "    \n",
    "    # Préparer les données de test sans l'identifiant\n",
    "    test = app_test.drop(columns=['SK_ID_CURR'])\n",
    "    \n",
    "    # S'assurer que les colonnes sont alignées avant l'imputation\n",
    "    common_cols = train.columns.intersection(test.columns)\n",
    "    train = train[common_cols]\n",
    "    test = test[common_cols]\n",
    "    \n",
    "    # Imputer les valeurs manquantes avec la médiane\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    train_numeric = imputer.fit_transform(train)\n",
    "    test_numeric = imputer.transform(test)\n",
    "    \n",
    "    # Normaliser les colonnes numériques\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_numeric = scaler.fit_transform(train_numeric)\n",
    "    test_numeric = scaler.transform(test_numeric)\n",
    "    \n",
    "    # Convertir les matrices numpy en DataFrames pandas\n",
    "    train_final = pd.DataFrame(train_numeric, columns=common_cols)\n",
    "    test_final = pd.DataFrame(test_numeric, columns=common_cols)\n",
    "    \n",
    "    print(\"Fin du nettoyage des données.\")\n",
    "    return train_final, test_final, train_labels, app_test['TARGET']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34786331-06d3-49ee-be7b-e074eb1c54f6",
   "metadata": {},
   "source": [
    "## Suppression Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "id": "ca76beb9-45e5-4713-9153-8b2f6448481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "class SuppressOutput:\n",
    "    \"\"\"Context manager to suppress stdout and stderr.\"\"\"\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        self._original_stderr = sys.stderr\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "        sys.stderr = open(os.devnull, 'w')\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        sys.stdout.close()\n",
    "        sys.stderr.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "        sys.stderr = self._original_stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dd5404-350f-472e-9740-ae8262a0afed",
   "metadata": {},
   "source": [
    "## Ponderation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "id": "43963251-9a8d-4ab6-ab28-252edaebee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(y):\n",
    "    \"\"\"Calculer les poids des classes pour un dataset déséquilibré.\"\"\"\n",
    "    print(\"Calcul de la pondération des classes...\")\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    \n",
    "    classes = np.unique(y)\n",
    "    class_weights = compute_class_weight('balanced', classes=classes, y=y)\n",
    "    class_weight_dict = dict(zip(classes, class_weights))\n",
    "    \n",
    "    print(f\"Pondération des classes: {class_weight_dict}\")\n",
    "    return class_weight_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21e229f-ee72-4a1b-aa19-2a32363a2a6d",
   "metadata": {},
   "source": [
    "## Recherche des HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "id": "a16afbf0-2354-4571-972b-209cfd970ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def search_hyperparameters(train_final, train_labels):\n",
    "    \"\"\"Rechercher les meilleurs hyperparamètres pour chaque modèle.\"\"\"\n",
    "    print(\"Début de la recherche des hyperparamètres...\")\n",
    "    \n",
    "    models = {}\n",
    "    \n",
    "    # LogisticRegression\n",
    "    log_reg_params = {'C': [1,0.1,10],'solver': ['newton-cg', 'lbfgs'],}\n",
    "    log_reg = LogisticRegression(max_iter=2500, class_weight='balanced')\n",
    "    log_reg_grid = GridSearchCV(log_reg, log_reg_params, cv=5, scoring='roc_auc')\n",
    "    log_reg_grid.fit(train_final, train_labels)\n",
    "    models['LogisticRegression'] = log_reg_grid.best_params_\n",
    "    \n",
    "    # DecisionTreeClassifier\n",
    "    tree_params = {'max_depth': [4,6,7], 'min_samples_split': [3, 4, 2]}\n",
    "    decision_tree = DecisionTreeClassifier(class_weight='balanced')\n",
    "    tree_grid = GridSearchCV(decision_tree, tree_params, cv=5, scoring='roc_auc')\n",
    "    tree_grid.fit(train_final, train_labels)\n",
    "    models['DecisionTreeClassifier'] = tree_grid.best_params_\n",
    "    \n",
    "    # RandomForestClassifier\n",
    "    rf_params = {'n_estimators': [300], 'max_depth': [5, 10,15]}\n",
    "    random_forest = RandomForestClassifier(n_jobs=-1, class_weight='balanced')\n",
    "    rf_grid = GridSearchCV(random_forest, rf_params, cv=5, scoring='roc_auc')\n",
    "    rf_grid.fit(train_final, train_labels)\n",
    "    models['RandomForestClassifier'] = rf_grid.best_params_\n",
    "    \n",
    "    # CatBoostClassifier\n",
    "    class_weights = calculate_class_weights(train_labels)\n",
    "    catboost_params = {'depth': [2, 3], 'learning_rate': [0.01, 0.1,], 'l2_leaf_reg': [5,6],'bagging_temperature': [0.3, 0.2],'loss_function': ['Logloss']}\n",
    "    catboost_model = CatBoostClassifier(iterations=500,auto_class_weights='Balanced', verbose=0)\n",
    "    catboost_grid = GridSearchCV(catboost_model, catboost_params, cv=5, scoring='roc_auc')\n",
    "    catboost_grid.fit(train_final, train_labels)\n",
    "    models['CatBoostClassifier'] = catboost_grid.best_params_\n",
    "    \n",
    "    # LightGBMClassifier\n",
    "    lightgbm_params = {\n",
    "        'n_estimators': [450],\n",
    "        'learning_rate': [0.1, 0.2],\n",
    "        'max_depth': [2, 3,],\n",
    "        'num_leaves': [2**6 - 1, 2**7 - 1, 2**8 - 1],\n",
    "        'verbosity': [-1]\n",
    "    }\n",
    "    lightgbm_model = lgb.LGBMClassifier()\n",
    "    lightgbm_grid = GridSearchCV(lightgbm_model, lightgbm_params, cv=5, scoring='roc_auc')\n",
    "    lightgbm_grid.fit(train_final, train_labels)\n",
    "    models['LightGBMClassifier'] = lightgbm_grid.best_params_\n",
    "    \n",
    "    print(\"Fin de la recherche des hyperparamètres.\")\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7f539f-2c91-4a2c-8d72-d86668c1bef8",
   "metadata": {},
   "source": [
    "## Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "id": "2cc2c7dd-36d0-47be-aa2b-a5336451f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "def train_models(train_final, train_labels, best_params):\n",
    "    \"\"\"Entraîne les modèles avec les meilleurs hyperparamètres trouvés et affiche les meilleurs paramètres.\"\"\"\n",
    "    print(\"Début de l'entraînement des modèles...\")\n",
    "    \n",
    "    models = {}\n",
    "    \n",
    "    # Logistic Regression\n",
    "    print(\"\\nEntraînement du modèle Logistic Regression...\")\n",
    "    log_reg_model = LogisticRegression(class_weight='balanced', max_iter=3000, **best_params['LogisticRegression'])\n",
    "    log_reg_model.fit(train_final, train_labels)\n",
    "    models['LogisticRegression'] = log_reg_model\n",
    "    print(\"Meilleurs paramètres pour Logistic Regression :\")\n",
    "    print(best_params['LogisticRegression'])\n",
    "    \n",
    "    # Decision Tree Classifier\n",
    "    print(\"\\nEntraînement du modèle Decision Tree Classifier...\")\n",
    "    decision_tree_model = DecisionTreeClassifier(class_weight='balanced', **best_params['DecisionTreeClassifier'])\n",
    "    decision_tree_model.fit(train_final, train_labels)\n",
    "    models['DecisionTreeClassifier'] = decision_tree_model\n",
    "    print(\"Meilleurs paramètres pour Decision Tree Classifier :\")\n",
    "    print(best_params['DecisionTreeClassifier'])\n",
    "    \n",
    "    # Random Forest Classifier\n",
    "    print(\"\\nEntraînement du modèle Random Forest Classifier...\")\n",
    "    random_forest_model = RandomForestClassifier(n_jobs=-1, class_weight='balanced', **best_params['RandomForestClassifier'])\n",
    "    random_forest_model.fit(train_final, train_labels)\n",
    "    models['RandomForestClassifier'] = random_forest_model\n",
    "    print(\"Meilleurs paramètres pour Random Forest Classifier :\")\n",
    "    print(best_params['RandomForestClassifier'])\n",
    "    \n",
    "    # CatBoost Classifier\n",
    "    print(\"\\nEntraînement du modèle CatBoost Classifier...\")\n",
    "    catboost_model = CatBoostClassifier(auto_class_weights='Balanced',silent=True, **best_params['CatBoostClassifier'])\n",
    "    catboost_model.fit(train_final, train_labels)\n",
    "    models['CatBoostClassifier'] = catboost_model\n",
    "    print(\"Meilleurs paramètres pour CatBoost Classifier :\")\n",
    "    print(best_params['CatBoostClassifier'])\n",
    "    \n",
    "    # LightGBM Classifier\n",
    "    print(\"\\nEntraînement du modèle LightGBM...\")\n",
    "    lightgbm_params = best_params['LightGBMClassifier']\n",
    "    lightgbm_params['verbosity'] = -1  # S'assurer que verbosity est désactivé\n",
    "    lightgbm_model = lgb.LGBMClassifier(class_weight='balanced', **lightgbm_params)\n",
    "    lightgbm_model.fit(train_final, train_labels)\n",
    "    models['LightGBMClassifier'] = lightgbm_model\n",
    "    print(\"Meilleurs paramètres pour LightGBM Classifier :\")\n",
    "    print(lightgbm_params)\n",
    "    \n",
    "    print(\"\\nFin de l'entraînement des modèles.\")\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cd42d6-efb2-4020-b755-d7da9de40f12",
   "metadata": {},
   "source": [
    "## Evaluation des perfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "id": "bbbb815b-e32e-44e4-bad6-f164af0e1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "\n",
    "def measure_prediction_time(model, X, n_estimations=1000):\n",
    "    \"\"\"Mesurer le temps de prédiction pour un nombre donné d'estimations.\n",
    "    \n",
    "    Args:\n",
    "        model: Le modèle à évaluer.\n",
    "        X: Les données d'entrée pour la prédiction.\n",
    "        n_estimations: Le nombre d'estimations à faire (par défaut 1000).\n",
    "\n",
    "    Returns:\n",
    "        avg_time: Temps moyen de prédiction pour une estimation, en secondes.\n",
    "        total_time: Temps total pour les 1000 prédictions, en secondes.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    for _ in range(n_estimations):\n",
    "        model.predict(X)\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    return total_time\n",
    "\n",
    "\n",
    "def evaluate_models(models, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Évaluer les performances des modèles sur les ensembles d'entraînement et de test.\"\"\"\n",
    "    print(\"Début de l'évaluation des modèles...\")\n",
    "    \n",
    "    metrics_train = []\n",
    "    metrics_test = []\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        if hasattr(model, 'predict'):\n",
    "            train_pred = model.predict(X_train)\n",
    "            test_pred = model.predict(X_test)\n",
    "            train_proba = model.predict_proba(X_train)[:, 1]\n",
    "            test_proba = model.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            train_pred = model.best_estimator_.predict(X_train)\n",
    "            test_pred = model.best_estimator_.predict(X_test)\n",
    "            train_proba = model.best_estimator_.predict_proba(X_train)[:, 1]\n",
    "            test_proba = model.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        train_auc = roc_auc_score(y_train, train_proba)\n",
    "        test_auc = roc_auc_score(y_test, test_proba)\n",
    "        train_precision = precision_score(y_train, train_pred, zero_division=0)\n",
    "        test_precision = precision_score(y_test, test_pred, zero_division=0)\n",
    "        train_recall = recall_score(y_train, train_pred, zero_division=0)\n",
    "        test_recall = recall_score(y_test, test_pred, zero_division=0)\n",
    "        train_f1 = f1_score(y_train, train_pred, zero_division=0)\n",
    "        test_f1 = f1_score(y_test, test_pred, zero_division=0)\n",
    "        train_cm = confusion_matrix(y_train, train_pred)\n",
    "        test_cm = confusion_matrix(y_test, test_pred)\n",
    "        \n",
    "        metrics_train.append([\n",
    "            name,\n",
    "            f\"{train_auc:.5f}\",\n",
    "            f\"{train_precision:.5f}\",\n",
    "            f\"{train_recall:.5f}\",\n",
    "            f\"{train_f1:.5f}\",\n",
    "            f\"{train_cm[0,0]} | {train_cm[0,1]}\\n{train_cm[1,0]} | {train_cm[1,1]}\",\n",
    "            measure_prediction_time(model, X_test)\n",
    "        ])\n",
    "        \n",
    "        metrics_test.append([\n",
    "            name,\n",
    "            f\"{test_auc:.5f}\",\n",
    "            f\"{test_precision:.5f}\",\n",
    "            f\"{test_recall:.5f}\",\n",
    "            f\"{test_f1:.5f}\",\n",
    "            f\"{test_cm[0,0]} | {test_cm[0,1]}\\n{test_cm[1,0]} | {test_cm[1,1]}\",\n",
    "            measure_prediction_time(model, X_test)\n",
    "        ])\n",
    "    \n",
    "    print(\"Fin de l'évaluation des modèles.\")\n",
    "    return metrics_train, metrics_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46faff85-18fc-49bd-982b-47d91564ac57",
   "metadata": {},
   "source": [
    "## Fonction principale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "id": "e73709b7-3266-4652-b80e-b5718a64ada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_predict(train_file, test_file):\n",
    "    \"\"\"Fonction principale pour nettoyer les données, rechercher les hyperparamètres,\n",
    "    entraîner les modèles, et évaluer les performances.\"\"\"\n",
    "    print(\"Début du traitement et des prédictions...\")\n",
    "    \n",
    "    # Nettoyage des données\n",
    "    train_final, test_final, train_labels, test_labels = clean_data(train_file, test_file)\n",
    "    \n",
    "    # Recherche des hyperparamètres\n",
    "    best_params = search_hyperparameters(train_final, train_labels)\n",
    "    \n",
    "    # Entraînement des modèles\n",
    "    models = train_models(train_final, train_labels, best_params)\n",
    "    \n",
    "    # Évaluation des performances\n",
    "    metrics_train, metrics_test = evaluate_models(models, train_final, train_labels, test_final, test_labels)\n",
    "    \n",
    "    # Affichage des résultats pour les données d'entraînement\n",
    "    headers_train = ['Model', 'ROC AUC', 'Precision', 'Recall', 'F1-Score', 'Confusion Matrix', 'Time (1000 estimations)']\n",
    "    results_table_train = tabulate(metrics_train, headers_train, tablefmt='pipe')\n",
    "    \n",
    "    print(\"\\nMétriques pour les données d'entraînement :\")\n",
    "    print(results_table_train)\n",
    "    \n",
    "    # Affichage des résultats pour les données de test\n",
    "    headers_test = ['Model', 'ROC AUC', 'Precision', 'Recall', 'F1-Score', 'Confusion Matrix', 'Time (1000 estimations)']\n",
    "    results_table_test = tabulate(metrics_test, headers_test, tablefmt='pipe')\n",
    "    \n",
    "    print(\"\\nMétriques pour les données de test :\")\n",
    "    print(results_table_test)\n",
    "    \n",
    "    print(\"Fin du traitement et des prédictions.\")\n",
    "    return metrics_train, metrics_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d035a9f-bf7f-4d5a-8c5b-270c33a6f751",
   "metadata": {},
   "source": [
    "## Appel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "id": "91b74b55-9b05-421d-bae5-4583cd861ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début du traitement et des prédictions...\n",
      "Début du nettoyage des données...\n",
      "Fin du nettoyage des données.\n",
      "Début de la recherche des hyperparamètres...\n",
      "Calcul de la pondération des classes...\n",
      "Pondération des classes: {0: 0.5436743868865709, 1: 6.224178811010872}\n",
      "Fin de la recherche des hyperparamètres.\n",
      "Début de l'entraînement des modèles...\n",
      "\n",
      "Entraînement du modèle Logistic Regression...\n",
      "Meilleurs paramètres pour Logistic Regression :\n",
      "{'C': 10, 'solver': 'newton-cg'}\n",
      "\n",
      "Entraînement du modèle Decision Tree Classifier...\n",
      "Meilleurs paramètres pour Decision Tree Classifier :\n",
      "{'max_depth': 6, 'min_samples_split': 3}\n",
      "\n",
      "Entraînement du modèle Random Forest Classifier...\n",
      "Meilleurs paramètres pour Random Forest Classifier :\n",
      "{'max_depth': 10, 'n_estimators': 300}\n",
      "\n",
      "Entraînement du modèle CatBoost Classifier...\n",
      "Meilleurs paramètres pour CatBoost Classifier :\n",
      "{'bagging_temperature': 0.3, 'depth': 3, 'l2_leaf_reg': 6, 'learning_rate': 0.1, 'loss_function': 'Logloss'}\n",
      "\n",
      "Entraînement du modèle LightGBM...\n",
      "Meilleurs paramètres pour LightGBM Classifier :\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 450, 'num_leaves': 63, 'verbosity': -1}\n",
      "\n",
      "Fin de l'entraînement des modèles.\n",
      "Début de l'évaluation des modèles...\n",
      "Fin de l'évaluation des modèles.\n",
      "\n",
      "Métriques pour les données d'entraînement :\n",
      "| Model                  |   ROC AUC |   Precision |   Recall |   F1-Score | Confusion Matrix   |   Time (1000 estimations) |\n",
      "|:-----------------------|----------:|------------:|---------:|-----------:|:-------------------|--------------------------:|\n",
      "| LogisticRegression     |   0.74739 |     0.15985 |  0.67748 |    0.25867 | 136394 | 61571     |                   4.33713 |\n",
      "|                        |           |             |          |            | 5577 | 11715       |                           |\n",
      "| DecisionTreeClassifier |   0.72289 |     0.1604  |  0.60421 |    0.2535  | 143276 | 54689     |                   8.2689  |\n",
      "|                        |           |             |          |            | 6844 | 10448       |                           |\n",
      "| RandomForestClassifier |   0.80729 |     0.194   |  0.71212 |    0.30493 | 146806 | 51159     |                 161.344   |\n",
      "|                        |           |             |          |            | 4978 | 12314       |                           |\n",
      "| CatBoostClassifier     |   0.79459 |     0.18302 |  0.72299 |    0.2921  | 142157 | 55808     |                  19.6767  |\n",
      "|                        |           |             |          |            | 4790 | 12502       |                           |\n",
      "| LightGBMClassifier     |   0.78976 |     0.17898 |  0.7175  |    0.28649 | 141051 | 56914     |                  79.8203  |\n",
      "|                        |           |             |          |            | 4885 | 12407       |                           |\n",
      "\n",
      "Métriques pour les données de test :\n",
      "| Model                  |   ROC AUC |   Precision |   Recall |   F1-Score | Confusion Matrix   |   Time (1000 estimations) |\n",
      "|:-----------------------|----------:|------------:|---------:|-----------:|:-------------------|--------------------------:|\n",
      "| LogisticRegression     |   0.74115 |     0.15971 |  0.66959 |    0.2579  | 58182 | 26539      |                   4.31363 |\n",
      "|                        |           |             |          |            | 2489 | 5044        |                           |\n",
      "| DecisionTreeClassifier |   0.71144 |     0.15792 |  0.58967 |    0.24912 | 61035 | 23686      |                   8.2064  |\n",
      "|                        |           |             |          |            | 3091 | 4442        |                           |\n",
      "| RandomForestClassifier |   0.72648 |     0.16589 |  0.59764 |    0.25969 | 62084 | 22637      |                 164.118   |\n",
      "|                        |           |             |          |            | 3031 | 4502        |                           |\n",
      "| CatBoostClassifier     |   0.7569  |     0.17039 |  0.66746 |    0.27148 | 60241 | 24480      |                  19.8728  |\n",
      "|                        |           |             |          |            | 2505 | 5028        |                           |\n",
      "| LightGBMClassifier     |   0.75689 |     0.16842 |  0.66879 |    0.26908 | 59846 | 24875      |                  82.0873  |\n",
      "|                        |           |             |          |            | 2495 | 5038        |                           |\n",
      "Fin du traitement et des prédictions.\n"
     ]
    }
   ],
   "source": [
    "# Appel de la fonction principale avec les chemins des fichiers\n",
    "metrics_train, metrics_test = process_and_predict('data/application_train_split.csv', 'data/application_test_split.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03ff006-3ea5-441f-be56-5197b69fbb41",
   "metadata": {},
   "source": [
    "# Avec feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfdaa1a-3c15-4a22-9a6f-42061f7235b7",
   "metadata": {},
   "source": [
    "## Nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "2283b627-bba2-44e3-9589-5448753e2407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def clean_data(train_file, test_file):\n",
    "    \"\"\"Nettoyer et préparer les données pour l'entraînement et le test.\"\"\"\n",
    "    print(\"Début du nettoyage des données...\")\n",
    "    \n",
    "    # Charger les données\n",
    "    app_train = pd.read_csv(train_file)\n",
    "    app_test = pd.read_csv(test_file)\n",
    "    \n",
    "    # Convertir toutes les colonnes en numériques en utilisant LabelEncoder\n",
    "    label_encoders = {}\n",
    "    for col in app_train.columns:\n",
    "        if app_train[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            app_train[col] = le.fit_transform(app_train[col].astype(str))\n",
    "            if col in app_test.columns:\n",
    "                app_test[col] = le.transform(app_test[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    # Appliquer l'ingénierie des fonctionnalités\n",
    "    app_train, app_test = feature_engineering(app_train, app_test)\n",
    "    \n",
    "    # Séparer les données d'entraînement et les labels\n",
    "    if 'TARGET' in app_train:\n",
    "        train = app_train.drop(columns=['TARGET'])\n",
    "        train_labels = app_train['TARGET']\n",
    "    else:\n",
    "        raise ValueError(\"La colonne 'TARGET' n'existe pas dans les données d'entraînement.\")\n",
    "    \n",
    "    # Préparer les données de test sans l'identifiant\n",
    "    test = app_test.drop(columns=['SK_ID_CURR'])\n",
    "    \n",
    "    # S'assurer que les colonnes sont alignées avant l'imputation\n",
    "    common_cols = train.columns.intersection(test.columns)\n",
    "    train = train[common_cols]\n",
    "    test = test[common_cols]\n",
    "    \n",
    "    # Imputer les valeurs manquantes avec la médiane\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    train_numeric = imputer.fit_transform(train)\n",
    "    test_numeric = imputer.transform(test)\n",
    "    \n",
    "    # Normaliser les colonnes numériques\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_numeric = scaler.fit_transform(train_numeric)\n",
    "    test_numeric = scaler.transform(test_numeric)\n",
    "    \n",
    "    # Convertir les matrices numpy en DataFrames pandas\n",
    "    train_final = pd.DataFrame(train_numeric, columns=common_cols)\n",
    "    test_final = pd.DataFrame(test_numeric, columns=common_cols)\n",
    "    \n",
    "    print(\"Fin du nettoyage des données.\")\n",
    "    return train_final, test_final, train_labels, app_test['TARGET']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8323f0a2-ece7-43bb-969b-6c0f9cb340df",
   "metadata": {},
   "source": [
    "## feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "d2fa0baf-fe8e-4eb3-b22d-b57fe3902287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(app_train, app_test):\n",
    "    \"\"\"Créer de nouvelles fonctionnalités à partir des données d'entraînement et de test.\"\"\"\n",
    "    # Création de nouvelles fonctionnalités\n",
    "    app_train['annuity_income_ratio'] = app_train['AMT_ANNUITY'] / app_train['AMT_INCOME_TOTAL']\n",
    "    app_test['annuity_income_ratio'] = app_test['AMT_ANNUITY'] / app_test['AMT_INCOME_TOTAL']\n",
    "    \n",
    "    app_train['credit_annuity_ratio'] = app_train['AMT_CREDIT'] / app_train['AMT_ANNUITY']\n",
    "    app_test['credit_annuity_ratio'] = app_test['AMT_CREDIT'] / app_test['AMT_ANNUITY']\n",
    "    \n",
    "    app_train['credit_goods_price_ratio'] = app_train['AMT_CREDIT'] / app_train['AMT_GOODS_PRICE']\n",
    "    app_test['credit_goods_price_ratio'] = app_test['AMT_CREDIT'] / app_test['AMT_GOODS_PRICE']\n",
    "    \n",
    "    app_train['credit_downpayment'] = app_train['AMT_GOODS_PRICE'] - app_train['AMT_CREDIT']\n",
    "    app_test['credit_downpayment'] = app_test['AMT_GOODS_PRICE'] - app_test['AMT_CREDIT']\n",
    "    \n",
    "    app_train['AGE_INT'] = (app_train['DAYS_BIRTH'] / -365).astype(int)\n",
    "    app_test['AGE_INT'] = (app_test['DAYS_BIRTH'] / -365).astype(int)\n",
    "    \n",
    "    return app_train, app_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470f9592-44c1-41b9-8721-06df888cf98e",
   "metadata": {},
   "source": [
    "## Recherche des Hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "01d43a4c-6e27-4b48-abb0-3ee773f22b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def search_hyperparameters(train_final, train_labels):\n",
    "    \"\"\"Rechercher les meilleurs hyperparamètres pour les modèles CatBoost et LogisticRegression.\"\"\"\n",
    "    print(\"Début de la recherche des hyperparamètres...\")\n",
    "    \n",
    "    models = {}\n",
    "    \n",
    "    # LogisticRegression\n",
    "    log_reg_params = {'C': [1, 0.1, 10], 'solver': ['newton-cg', 'lbfgs'],'penalty': ['l2']}\n",
    "    log_reg = LogisticRegression(max_iter=5000, class_weight='balanced')\n",
    "    log_reg_grid = GridSearchCV(log_reg, log_reg_params, cv=5, scoring='roc_auc')\n",
    "    log_reg_grid.fit(train_final, train_labels)\n",
    "    models['LogisticRegression'] = log_reg_grid.best_params_\n",
    "    \n",
    "    # CatBoostClassifier\n",
    "    catboost_params = {\n",
    "        'depth': [2, 3],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'l2_leaf_reg': [5, 6],\n",
    "        'bagging_temperature': [0.3, 0.2],\n",
    "        'loss_function': ['Logloss']\n",
    "    }\n",
    "    catboost_model = CatBoostClassifier(iterations=500, auto_class_weights='Balanced', verbose=0)\n",
    "    catboost_grid = GridSearchCV(catboost_model, catboost_params, cv=5, scoring='roc_auc')\n",
    "    catboost_grid.fit(train_final, train_labels)\n",
    "    models['CatBoostClassifier'] = catboost_grid.best_params_\n",
    "    \n",
    "    print(\"Fin de la recherche des hyperparamètres.\")\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168ce4fa-bc51-46b4-9f63-765dedde80b2",
   "metadata": {},
   "source": [
    "## Entraînement des Modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "7f6194f1-387e-45d6-be51-f85b68e6f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def train_models(train_final, train_labels, best_params):\n",
    "    \"\"\"Entraîne les modèles CatBoost et LogisticRegression avec les meilleurs hyperparamètres trouvés et affiche les meilleurs paramètres.\"\"\"\n",
    "    print(\"Début de l'entraînement des modèles...\")\n",
    "    \n",
    "    models = {}\n",
    "    \n",
    "    # Logistic Regression\n",
    "    print(\"\\nEntraînement du modèle Logistic Regression...\")\n",
    "    log_reg_model = LogisticRegression(class_weight='balanced', max_iter=6000, **best_params['LogisticRegression'])\n",
    "    log_reg_model.fit(train_final, train_labels)\n",
    "    models['LogisticRegression'] = log_reg_model\n",
    "    print(\"Meilleurs paramètres pour Logistic Regression :\")\n",
    "    print(best_params['LogisticRegression'])\n",
    "    \n",
    "    # CatBoost Classifier\n",
    "    print(\"\\nEntraînement du modèle CatBoost Classifier...\")\n",
    "    catboost_model = CatBoostClassifier(auto_class_weights='Balanced', silent=True, **best_params['CatBoostClassifier'])\n",
    "    catboost_model.fit(train_final, train_labels)\n",
    "    models['CatBoostClassifier'] = catboost_model\n",
    "    print(\"Meilleurs paramètres pour CatBoost Classifier :\")\n",
    "    print(best_params['CatBoostClassifier'])\n",
    "    \n",
    "    print(\"\\nFin de l'entraînement des modèles.\")\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6cf625-36ea-4129-9647-ddb53d296642",
   "metadata": {},
   "source": [
    "## Évaluation des Modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "976c26db-cd4b-4ca7-a801-e343d46cadc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def measure_prediction_time(model, X, n_estimations=1000):\n",
    "    \"\"\"Mesurer le temps de prédiction pour un nombre donné d'estimations.\"\"\"\n",
    "    start_time = time.time()\n",
    "    for _ in range(n_estimations):\n",
    "        model.predict(X)\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    return total_time\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "from tabulate import tabulate\n",
    "\n",
    "def evaluate_models(models, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Évaluer les performances des modèles CatBoost et LogisticRegression sur les ensembles d'entraînement et de test.\"\"\"\n",
    "    print(\"Début de l'évaluation des modèles...\")\n",
    "    \n",
    "    metrics_train = []\n",
    "    metrics_test = []\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        if hasattr(model, 'predict'):\n",
    "            train_pred = model.predict(X_train)\n",
    "            test_pred = model.predict(X_test)\n",
    "            train_proba = model.predict_proba(X_train)[:, 1]\n",
    "            test_proba = model.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            train_pred = model.best_estimator_.predict(X_train)\n",
    "            test_pred = model.best_estimator_.predict(X_test)\n",
    "            train_proba = model.best_estimator_.predict_proba(X_train)[:, 1]\n",
    "            test_proba = model.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        train_auc = roc_auc_score(y_train, train_proba)\n",
    "        test_auc = roc_auc_score(y_test, test_proba)\n",
    "        train_precision = precision_score(y_train, train_pred, zero_division=0)\n",
    "        test_precision = precision_score(y_test, test_pred, zero_division=0)\n",
    "        train_recall = recall_score(y_train, train_pred, zero_division=0)\n",
    "        test_recall = recall_score(y_test, test_pred, zero_division=0)\n",
    "        train_f1 = f1_score(y_train, train_pred, zero_division=0)\n",
    "        test_f1 = f1_score(y_test, test_pred, zero_division=0)\n",
    "        train_cm = confusion_matrix(y_train, train_pred)\n",
    "        test_cm = confusion_matrix(y_test, test_pred)\n",
    "        \n",
    "        metrics_train.append([\n",
    "            name,\n",
    "            f\"{train_auc:.5f}\",\n",
    "            f\"{train_precision:.5f}\",\n",
    "            f\"{train_recall:.5f}\",\n",
    "            f\"{train_f1:.5f}\",\n",
    "            f\"{train_cm[0,0]} | {train_cm[0,1]}\\n{train_cm[1,0]} | {train_cm[1,1]}\",\n",
    "            measure_prediction_time(model, X_test)\n",
    "        ])\n",
    "        \n",
    "        metrics_test.append([\n",
    "            name,\n",
    "            f\"{test_auc:.5f}\",\n",
    "            f\"{test_precision:.5f}\",\n",
    "            f\"{test_recall:.5f}\",\n",
    "            f\"{test_f1:.5f}\",\n",
    "            f\"{test_cm[0,0]} | {test_cm[0,1]}\\n{test_cm[1,0]} | {test_cm[1,1]}\",\n",
    "            measure_prediction_time(model, X_test)\n",
    "        ])\n",
    "    \n",
    "    print(\"Fin de l'évaluation des modèles.\")\n",
    "    return metrics_train, metrics_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a9bf1c-1ea4-4933-baa8-fe49e520fa5e",
   "metadata": {},
   "source": [
    "## Fonction Principale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "cbfe20e4-be15-4c40-9db9-8982769339fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_predict(train_file, test_file):\n",
    "    \"\"\"Fonction principale pour nettoyer les données, rechercher les hyperparamètres,\n",
    "    entraîner les modèles, et évaluer les performances.\"\"\"\n",
    "    print(\"Début du traitement et des prédictions...\")\n",
    "    \n",
    "    # Nettoyage des données\n",
    "    train_final, test_final, train_labels, test_labels = clean_data(train_file, test_file)\n",
    "    \n",
    "    # Recherche des hyperparamètres\n",
    "    best_params = search_hyperparameters(train_final, train_labels)\n",
    "    \n",
    "    # Entraînement des modèles\n",
    "    models = train_models(train_final, train_labels, best_params)\n",
    "    \n",
    "    # Évaluation des performances\n",
    "    metrics_train, metrics_test = evaluate_models(models, train_final, train_labels, test_final, test_labels)\n",
    "    \n",
    "    # Affichage des résultats pour les données d'entraînement\n",
    "    headers_train = ['Model', 'ROC AUC', 'Precision', 'Recall', 'F1-Score', 'Confusion Matrix', 'Time (1000 estimations)']\n",
    "    results_table_train = tabulate(metrics_train, headers_train, tablefmt='pipe')\n",
    "    \n",
    "    print(\"\\nMétriques pour les données d'entraînement :\")\n",
    "    print(results_table_train)\n",
    "    \n",
    "    # Affichage des résultats pour les données de test\n",
    "    headers_test = ['Model', 'ROC AUC', 'Precision', 'Recall', 'F1-Score', 'Confusion Matrix', 'Time (1000 estimations)']\n",
    "    results_table_test = tabulate(metrics_test, headers_test, tablefmt='pipe')\n",
    "    \n",
    "    print(\"\\nMétriques pour les données de test :\")\n",
    "    print(results_table_test)\n",
    "    \n",
    "    print(\"Fin du traitement et des prédictions.\")\n",
    "    return metrics_train, metrics_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f32d20-e9bf-4718-a06b-1cda4bd7511e",
   "metadata": {},
   "source": [
    "## Appel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "f594b30a-ba7d-4a37-bf9b-ba3c34304af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début du traitement et des prédictions...\n",
      "Début du nettoyage des données...\n",
      "Fin du nettoyage des données.\n",
      "Début de la recherche des hyperparamètres...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin de la recherche des hyperparamètres.\n",
      "Début de l'entraînement des modèles...\n",
      "\n",
      "Entraînement du modèle Logistic Regression...\n",
      "Meilleurs paramètres pour Logistic Regression :\n",
      "{'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "\n",
      "Entraînement du modèle CatBoost Classifier...\n",
      "Meilleurs paramètres pour CatBoost Classifier :\n",
      "{'bagging_temperature': 0.3, 'depth': 3, 'l2_leaf_reg': 6, 'learning_rate': 0.1, 'loss_function': 'Logloss'}\n",
      "\n",
      "Fin de l'entraînement des modèles.\n",
      "Début de l'évaluation des modèles...\n",
      "Fin de l'évaluation des modèles.\n",
      "\n",
      "Métriques pour les données d'entraînement :\n",
      "| Model              |   ROC AUC |   Precision |   Recall |   F1-Score | Confusion Matrix   |   Time (1000 estimations) |\n",
      "|:-------------------|----------:|------------:|---------:|-----------:|:-------------------|--------------------------:|\n",
      "| LogisticRegression |   0.74828 |     0.16002 |  0.67609 |    0.25878 | 136595 | 61370     |                    4.2895 |\n",
      "|                    |           |             |          |            | 5601 | 11691       |                           |\n",
      "| CatBoostClassifier |   0.80158 |     0.18757 |  0.72854 |    0.29833 | 143397 | 54568     |                   19.4214 |\n",
      "|                    |           |             |          |            | 4694 | 12598       |                           |\n",
      "\n",
      "Métriques pour les données de test :\n",
      "| Model              |   ROC AUC |   Precision |   Recall |   F1-Score | Confusion Matrix   |   Time (1000 estimations) |\n",
      "|:-------------------|----------:|------------:|---------:|-----------:|:-------------------|--------------------------:|\n",
      "| LogisticRegression |   0.74171 |     0.16012 |  0.66919 |    0.25841 | 58280 | 26441      |                   4.28007 |\n",
      "|                    |           |             |          |            | 2492 | 5041        |                           |\n",
      "| CatBoostClassifier |   0.76564 |     0.17527 |  0.6737  |    0.27817 | 60840 | 23881      |                  19.3178  |\n",
      "|                    |           |             |          |            | 2458 | 5075        |                           |\n",
      "Fin du traitement et des prédictions.\n"
     ]
    }
   ],
   "source": [
    "# Appel de la fonction principale avec les chemins des fichiers\n",
    "metrics_train, metrics_test = process_and_predict('data/application_train_split.csv', 'data/application_test_split.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c74347a-d801-4cb3-8a22-4abae31e85a8",
   "metadata": {},
   "source": [
    "# Avec feature engineering V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8643829-bcf2-42f2-9b05-21365719e102",
   "metadata": {},
   "source": [
    "## feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d86cd986-792c-4f9d-bc73-373fc91a987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(train, test):\n",
    "    \"\"\"Créer de nouvelles fonctionnalités à partir des données existantes.\"\"\"\n",
    "    train['AMT_ANNUITY/INCOME'] = train['AMT_ANNUITY'] / train['AMT_INCOME_TOTAL']\n",
    "    test['AMT_ANNUITY/INCOME'] = test['AMT_ANNUITY'] / test['AMT_INCOME_TOTAL']\n",
    "    \n",
    "    train['credit_annuity_ratio'] = train['AMT_CREDIT'] / train['AMT_ANNUITY']\n",
    "    test['credit_annuity_ratio'] = test['AMT_CREDIT'] / test['AMT_ANNUITY']\n",
    "    \n",
    "    train['credit_goods_price_ratio'] = train['AMT_CREDIT'] / train['AMT_GOODS_PRICE']\n",
    "    test['credit_goods_price_ratio'] = test['AMT_CREDIT'] / test['AMT_GOODS_PRICE']\n",
    "    \n",
    "    train['credit_downpayment'] = train['AMT_GOODS_PRICE'] - train['AMT_CREDIT']\n",
    "    test['credit_downpayment'] = test['AMT_GOODS_PRICE'] - test['AMT_CREDIT']\n",
    "    \n",
    "    train['AGE_INT'] = (train['DAYS_BIRTH'] / -365).astype(int)\n",
    "    test['AGE_INT'] = (test['DAYS_BIRTH'] / -365).astype(int)\n",
    "    \n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50bfb54-47e5-4cd5-8b3b-9df052e62aa8",
   "metadata": {},
   "source": [
    "## Nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "5c80fc23-e802-4d96-84f1-18846a78e3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def clean_data(train_file, test_file):\n",
    "    \"\"\"Nettoyer et préparer les données pour l'entraînement et le test.\"\"\"\n",
    "    print(\"Début du nettoyage des données...\")\n",
    "    \n",
    "    app_train = pd.read_csv(train_file)\n",
    "    app_test = pd.read_csv(test_file)\n",
    "    \n",
    "    label_encoders = {}\n",
    "    for col in app_train.columns:\n",
    "        if app_train[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            app_train[col] = le.fit_transform(app_train[col].astype(str))\n",
    "            if col in app_test.columns:\n",
    "                app_test[col] = le.transform(app_test[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    app_train, app_test = feature_engineering(app_train, app_test)\n",
    "    \n",
    "    if 'TARGET' in app_train:\n",
    "        train = app_train.drop(columns=['TARGET'])\n",
    "        train_labels = app_train['TARGET']\n",
    "    else:\n",
    "        raise ValueError(\"La colonne 'TARGET' n'existe pas dans les données d'entraînement.\")\n",
    "    \n",
    "    test = app_test.drop(columns=['SK_ID_CURR'])\n",
    "    \n",
    "    common_cols = train.columns.intersection(test.columns)\n",
    "    train = train[common_cols]\n",
    "    test = test[common_cols]\n",
    "    \n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    train_numeric = imputer.fit_transform(train)\n",
    "    test_numeric = imputer.transform(test)\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_numeric = scaler.fit_transform(train_numeric)\n",
    "    test_numeric = scaler.transform(test_numeric)\n",
    "    \n",
    "    train_final = pd.DataFrame(train_numeric, columns=common_cols)\n",
    "    test_final = pd.DataFrame(test_numeric, columns=common_cols)\n",
    "    \n",
    "    print(\"Fin du nettoyage des données.\")\n",
    "    return train_final, test_final, train_labels, app_test['TARGET']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4586d1e9-c7d5-4599-93fc-b0aacdaf6392",
   "metadata": {},
   "source": [
    "## RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "3683ed37-813e-4d1b-b70a-d0343aec938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def apply_rfe_to_feature_engineering(X, y, engineered_features):\n",
    "    \"\"\"Appliquer RFE uniquement sur les caractéristiques issues du feature engineering.\"\"\"\n",
    "    X_engineered = X[engineered_features]\n",
    "    \n",
    "    clf = LogisticRegression(max_iter=5000)\n",
    "    cv = StratifiedKFold(5)\n",
    "    \n",
    "    rfecv = RFECV(\n",
    "        estimator=clf,\n",
    "        step=1,\n",
    "        cv=cv,\n",
    "        scoring=\"accuracy\",\n",
    "        min_features_to_select=2,\n",
    "        n_jobs=2\n",
    "    )\n",
    "    \n",
    "    rfecv.fit(X_engineered, y)\n",
    "    \n",
    "    selected_features = [feature for feature, selected in zip(engineered_features, rfecv.support_) if selected]\n",
    "    print(f\"Optimal number of features: {rfecv.n_features_}\")\n",
    "    print(f\"Selected features: {selected_features}\")\n",
    "    \n",
    "    return selected_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d915f78-f9d2-41ad-bca3-c802a003551c",
   "metadata": {},
   "source": [
    "## Entraînement des Modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "2351a1e4-75c0-40f9-815f-013423f1fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def train_models(train_final, train_labels, best_params):\n",
    "    \"\"\"Entraîner les modèles en utilisant les paramètres optimaux et RFE pour le feature engineering.\"\"\"\n",
    "    \n",
    "    # Les caractéristiques issues du feature engineering\n",
    "    engineered_features = [\n",
    "        'AMT_ANNUITY/INCOME', \n",
    "        'credit_annuity_ratio', \n",
    "        'credit_goods_price_ratio', \n",
    "        'credit_downpayment', \n",
    "        'AGE_INT'\n",
    "    ]\n",
    "    \n",
    "    # Appliquer RFE uniquement sur ces nouvelles caractéristiques\n",
    "    selected_engineered_features = apply_rfe_to_feature_engineering(train_final, train_labels, engineered_features)\n",
    "    \n",
    "    # Conserver les autres caractéristiques non issues du feature engineering\n",
    "    other_features = [col for col in train_final.columns if col not in engineered_features]\n",
    "    \n",
    "    # Créer une liste des caractéristiques finales à utiliser\n",
    "    final_features = other_features + selected_engineered_features\n",
    "    \n",
    "    # Sélectionner les données d'entraînement finales\n",
    "    X_train = train_final[final_features]\n",
    "    \n",
    "    # Entraîner les modèles avec les caractéristiques sélectionnées\n",
    "    models = {}\n",
    "    \n",
    "    # Logistic Regression avec class_weight\n",
    "    clf = LogisticRegression(**best_params['LogisticRegression'])\n",
    "    clf.fit(X_train, train_labels)\n",
    "    models['Logistic Regression'] = clf\n",
    "    \n",
    "    # CatBoost Classifier (pas de class_weight spécifique, mais CatBoost gère le déséquilibre en interne)\n",
    "    clf_catboost = CatBoostClassifier(**best_params['CatBoostClassifier'])\n",
    "    clf_catboost.fit(X_train, train_labels, verbose=0)\n",
    "    models['CatBoost Classifier'] = clf_catboost\n",
    "    \n",
    "    return models, final_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d957a7a4-7520-4d39-a858-83013864795c",
   "metadata": {},
   "source": [
    "## Recherche des Hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "a707613f-d384-4ac9-ae02-40227a41cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def search_hyperparameters(train_final, train_labels):\n",
    "    \"\"\"Rechercher les meilleurs hyperparamètres pour les modèles.\"\"\"\n",
    "    print(\"Début de la recherche des hyperparamètres...\")\n",
    "    \n",
    "    models = {}\n",
    "    \n",
    "    # Hyperparamètres pour Logistic Regression\n",
    "    log_reg_params = {\n",
    "        'C': [100, 10],\n",
    "        'solver': ['newton-cg', 'lbfgs'],\n",
    "        'penalty': ['l2'],\n",
    "        'class_weight': ['balanced']  # Ajout de la pondération des classes\n",
    "    }\n",
    "    log_reg = LogisticRegression(max_iter=7000, class_weight='balanced')\n",
    "    log_reg_grid = GridSearchCV(log_reg, log_reg_params, cv=5, scoring='roc_auc')\n",
    "    log_reg_grid.fit(train_final, train_labels)\n",
    "    models['LogisticRegression'] = log_reg_grid.best_params_\n",
    "    \n",
    "    # Hyperparamètres pour CatBoostClassifier\n",
    "    catboost_params = {\n",
    "        'depth': [1, 2, 3],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'l2_leaf_reg': [6,7],\n",
    "        'bagging_temperature': [0.3, 0.2, 0.1],\n",
    "        'loss_function': ['Logloss'],\n",
    "        'auto_class_weights' : ['Balanced'],\n",
    "    }\n",
    "    catboost_model = CatBoostClassifier(iterations=10, verbose=0)\n",
    "    catboost_grid = GridSearchCV(catboost_model, catboost_params, cv=5, scoring='roc_auc')\n",
    "    catboost_grid.fit(train_final, train_labels)\n",
    "    models['CatBoostClassifier'] = catboost_grid.best_params_\n",
    "    \n",
    "    print(\"Fin de la recherche des hyperparamètres.\")\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8964b9-b25b-4a00-b881-1ffb9bc013f4",
   "metadata": {},
   "source": [
    "## Évaluation des Modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b4e7f0e6-812c-49d5-aafa-ebc1dc8639ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def measure_prediction_time(model, X, n_estimations=1000):\n",
    "    \"\"\"Mesurer le temps de prédiction pour un nombre donné d'estimations.\"\"\"\n",
    "    start_time = time.time()\n",
    "    for _ in range(n_estimations):\n",
    "        model.predict(X)\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    return total_time\n",
    "\n",
    "def evaluate_models(models, X_train, y_train, X_test, y_test, selected_features):\n",
    "    \"\"\"Évaluer les modèles en termes de performances et de temps de prédiction, et afficher les meilleurs hyperparamètres.\"\"\"\n",
    "    \n",
    "    metrics_train = []\n",
    "    metrics_test = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        # Prédictions pour l'entraînement et le test\n",
    "        train_pred = model.predict(X_train)\n",
    "        test_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculer les probabilités pour ROC AUC\n",
    "        train_proba = model.predict_proba(X_train)[:, 1]\n",
    "        test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Mesurer le temps de prédiction pour 1000 estimations\n",
    "        estimation_time_train = measure_prediction_time(model, X_train, n_estimations=1000)\n",
    "        estimation_time_test = measure_prediction_time(model, X_test, n_estimations=1000)\n",
    "\n",
    "        # Enregistrer les métriques pour les données d'entraînement\n",
    "        metrics_train.append({\n",
    "            'Model': name,\n",
    "            'ROC AUC': round(roc_auc_score(y_train, train_proba), 5),\n",
    "            'Precision': round(precision_score(y_train, train_pred), 5),\n",
    "            'Recall': round(recall_score(y_train, train_pred), 5),\n",
    "            'F1-Score': round(f1_score(y_train, train_pred), 5),\n",
    "            'Confusion Matrix': str(confusion_matrix(y_train, train_pred)),\n",
    "            'Time (1000 estimations)': round(estimation_time_train, 2)\n",
    "        })\n",
    "\n",
    "        # Enregistrer les métriques pour les données de test\n",
    "        metrics_test.append({\n",
    "            'Model': name,\n",
    "            'ROC AUC': round(roc_auc_score(y_test, test_proba), 5),\n",
    "            'Precision': round(precision_score(y_test, test_pred), 5),\n",
    "            'Recall': round(recall_score(y_test, test_pred), 5),\n",
    "            'F1-Score': round(f1_score(y_test, test_pred), 5),\n",
    "            'Confusion Matrix': str(confusion_matrix(y_test, test_pred)),\n",
    "            'Time (1000 estimations)': round(estimation_time_test, 2)\n",
    "        })\n",
    "\n",
    "        # Afficher les meilleurs hyperparamètres du modèle\n",
    "        print(f\"Best Hyperparameters for {name}:\")\n",
    "        print(model.get_params())\n",
    "\n",
    "    return metrics_train, metrics_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d2813-7912-45a9-bc0e-71a9b648609b",
   "metadata": {},
   "source": [
    "## Afichage resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "4a82f814-a5f1-472b-9e7f-32f1b55714e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def display_results(metrics_train, metrics_test):\n",
    "    \"\"\"Afficher les résultats des modèles avec tabulate, en incluant l'estimation des 1000 prédictions et en formatant les scores.\"\"\"\n",
    "\n",
    "    # Affichage des résultats pour les données d'entraînement\n",
    "    if metrics_train and isinstance(metrics_train, list) and all(isinstance(d, dict) for d in metrics_train):\n",
    "        headers_train = metrics_train[0].keys()\n",
    "        results_table_train = tabulate(\n",
    "            [[f\"{value:.5f}\" if isinstance(value, (float, int)) else value for value in d.values()] for d in metrics_train],\n",
    "            headers=headers_train,\n",
    "            tablefmt='pipe',\n",
    "            floatfmt=\".5f\"\n",
    "        )\n",
    "        print(\"\\nMétriques pour les données d'entraînement :\")\n",
    "        print(results_table_train)\n",
    "    else:\n",
    "        print(\"Erreur : Les données pour l'entraînement ne sont pas au format attendu ou sont vides.\")\n",
    "\n",
    "    # Affichage des résultats pour les données de test\n",
    "    if metrics_test and isinstance(metrics_test, list) and all(isinstance(d, dict) for d in metrics_test):\n",
    "        headers_test = metrics_test[0].keys()\n",
    "        results_table_test = tabulate(\n",
    "            [[f\"{value:.5f}\" if isinstance(value, (float, int)) else value for value in d.values()] for d in metrics_test],\n",
    "            headers=headers_test,\n",
    "            tablefmt='pipe',\n",
    "            floatfmt=\".5f\"\n",
    "        )\n",
    "        print(\"\\nMétriques pour les données de test :\")\n",
    "        print(results_table_test)\n",
    "    else:\n",
    "        print(\"Erreur : Les données pour le test ne sont pas au format attendu ou sont vides.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6ac7e5-535b-4bf5-84f3-9fbdf73b35c0",
   "metadata": {},
   "source": [
    "## Fonction Principale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "40e42038-fd46-408c-ac46-76e913c63471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_predict(train_file, test_file):\n",
    "    \"\"\"Fonction principale pour nettoyer les données, rechercher les hyperparamètres,\n",
    "    entraîner les modèles, et évaluer les performances.\"\"\"\n",
    "    print(\"Début du traitement et des prédictions...\")\n",
    "    \n",
    "    # Nettoyage des données\n",
    "    train_final, test_final, train_labels, test_labels = clean_data(train_file, test_file)\n",
    "    \n",
    "    # Recherche des hyperparamètres\n",
    "    best_params = search_hyperparameters(train_final, train_labels)\n",
    "    \n",
    "    # Entraînement des modèles\n",
    "    models, selected_features = train_models(train_final, train_labels, best_params)\n",
    "    \n",
    "    # Évaluation des performances\n",
    "    metrics_train, metrics_test = evaluate_models(models, train_final, train_labels, test_final, test_labels, selected_features)\n",
    "    \n",
    "    # Affichage des résultats\n",
    "    display_results(metrics_train, metrics_test)\n",
    "    \n",
    "    print(\"Fin du traitement et des prédictions.\")\n",
    "    return metrics_train, metrics_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3de7f2-42bc-4f47-95c7-601c79e5cc84",
   "metadata": {},
   "source": [
    "## Appel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "fb40bb7c-f656-4608-9763-0369cfe0e856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début du traitement et des prédictions...\n",
      "Début du nettoyage des données...\n",
      "Fin du nettoyage des données.\n",
      "Début de la recherche des hyperparamètres...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin de la recherche des hyperparamètres.\n",
      "Optimal number of features: 5\n",
      "Selected features: ['AMT_ANNUITY/INCOME', 'credit_annuity_ratio', 'credit_goods_price_ratio', 'credit_downpayment', 'AGE_INT']\n",
      "Best Hyperparameters for Logistic Regression:\n",
      "{'C': 100, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Best Hyperparameters for CatBoost Classifier:\n",
      "{'learning_rate': 0.1, 'depth': 3, 'l2_leaf_reg': 7, 'loss_function': 'Logloss', 'auto_class_weights': 'Balanced', 'bagging_temperature': 0.3}\n",
      "\n",
      "Métriques pour les données d'entraînement :\n",
      "| Model               |   ROC AUC |   Precision |   Recall |   F1-Score | Confusion Matrix   |   Time (1000 estimations) |\n",
      "|:--------------------|----------:|------------:|---------:|-----------:|:-------------------|--------------------------:|\n",
      "| Logistic Regression |   0.74856 |     0.16008 |  0.67690 |    0.25893 | [[136551  61414]   |                   9.19000 |\n",
      "|                     |           |             |          |            |  [  5587  11705]]  |                           |\n",
      "| CatBoost Classifier |   0.80139 |     0.18735 |  0.72872 |    0.29807 | [[143306  54659]   |                  41.46000 |\n",
      "|                     |           |             |          |            |  [  4691  12601]]  |                           |\n",
      "\n",
      "Métriques pour les données de test :\n",
      "| Model               |   ROC AUC |   Precision |   Recall |   F1-Score | Confusion Matrix   |   Time (1000 estimations) |\n",
      "|:--------------------|----------:|------------:|---------:|-----------:|:-------------------|--------------------------:|\n",
      "| Logistic Regression |   0.74179 |     0.16040 |  0.67105 |    0.25891 | [[58261 26460]     |                   4.70000 |\n",
      "|                     |           |             |          |            |  [ 2478  5055]]    |                           |\n",
      "| CatBoost Classifier |   0.76595 |     0.17498 |  0.67317 |    0.27776 | [[60812 23909]     |                  19.71000 |\n",
      "|                     |           |             |          |            |  [ 2462  5071]]    |                           |\n",
      "Fin du traitement et des prédictions.\n"
     ]
    }
   ],
   "source": [
    "# Appel de la fonction principale avec les chemins des fichiers\n",
    "metrics_train, metrics_test = process_and_predict('data/application_train_split.csv', 'data/application_test_split.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d021450c-8e93-4d4a-aa32-3d87fa71a779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8141e3-f575-4f2e-af23-3a0e1be2be75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
