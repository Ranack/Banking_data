{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6618adf7-185b-4be7-b511-ac8969c37529",
   "metadata": {},
   "source": [
    "# dummy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8f5586e6-8e80-4953-8a27-050ff2e31304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données...\n",
      "Données chargées avec succès.\n",
      "\n",
      "Préparation des données...\n",
      "Distribution des classes dans la cible :\n",
      "TARGET\n",
      "0    0.919271\n",
      "1    0.080729\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "\n",
      "Division des données en ensemble d'entraînement et de test...\n",
      "Division effectuée avec succès.\n",
      "\n",
      "Entraînement du DummyClassifier...\n",
      "Évaluation du modèle...\n",
      "Score d'entraînement du DummyClassifier: 0.919205879483594\n",
      "Score de test du DummyClassifier: 0.9195323805342829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1. Charger les données\n",
    "print(\"Chargement des données...\")\n",
    "df = pd.read_csv('data/application_train.csv')\n",
    "print(\"Données chargées avec succès.\\n\")\n",
    "\n",
    "# 2. Préparer les données (utiliser toutes les colonnes comme caractéristiques)\n",
    "print(\"Préparation des données...\")\n",
    "X = df.drop(columns=['TARGET'])\n",
    "y = df['TARGET']\n",
    "\n",
    "# Remplacer les valeurs manquantes pour les colonnes numériques\n",
    "X = X.fillna(X.median(numeric_only=True))  # Utiliser median pour les colonnes numériques\n",
    "\n",
    "# Identifier les colonnes numériques et catégorielles\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Prétraitement des caractéristiques\n",
    "numeric_transformer = SimpleImputer(strategy='median')\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Créer un pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DummyClassifier(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "# 3. Vérifier la distribution des classes\n",
    "print(\"Distribution des classes dans la cible :\")\n",
    "print(y.value_counts(normalize=True))\n",
    "print(\"\\n\")\n",
    "\n",
    "# 4. Diviser les données en ensemble d'entraînement et de test\n",
    "print(\"Division des données en ensemble d'entraînement et de test...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Division effectuée avec succès.\\n\")\n",
    "\n",
    "# 5. Entraîner et évaluer le DummyClassifier\n",
    "print(\"Entraînement du DummyClassifier...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 6. Évaluation du modèle\n",
    "print(\"Évaluation du modèle...\")\n",
    "train_score = pipeline.score(X_train, y_train)\n",
    "test_score = pipeline.score(X_test, y_test)\n",
    "print(f\"Score d'entraînement du DummyClassifier: {train_score}\")\n",
    "print(f\"Score de test du DummyClassifier: {test_score}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a20bab-1289-4310-898c-8d2cea2fe7ee",
   "metadata": {},
   "source": [
    "# régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7f82790d-393e-4cfe-b9e1-4344ca280a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données...\n",
      "Données chargées avec succès.\n",
      "\n",
      "Préparation des données...\n",
      "Division des données en ensemble d'entraînement et de test...\n",
      "Division effectuée avec succès.\n",
      "\n",
      "Entraînement du modèle de régression logistique...\n",
      "Évaluation du modèle...\n",
      "Score d'entraînement du modèle de régression logistique: 0.9189805674147646\n",
      "Score de test du modèle de régression logistique: 0.9199059119387777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1. Charger les données\n",
    "print(\"Chargement des données...\")\n",
    "df = pd.read_csv('data/application_train.csv')\n",
    "print(\"Données chargées avec succès.\\n\")\n",
    "\n",
    "# 2. Préparer les données (utiliser toutes les colonnes comme caractéristiques)\n",
    "print(\"Préparation des données...\")\n",
    "X = df.drop(columns=['TARGET'])\n",
    "y = df['TARGET']\n",
    "\n",
    "# Remplacer les valeurs manquantes pour les colonnes numériques\n",
    "X = X.fillna(X.median(numeric_only=True))  # Utiliser median pour les colonnes numériques\n",
    "\n",
    "# Identifier les colonnes numériques et catégorielles\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Prétraitement des caractéristiques\n",
    "numeric_transformer = SimpleImputer(strategy='median')\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Créer un pipeline avec LogisticRegression\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(solver='liblinear'))\n",
    "])\n",
    "\n",
    "# 3. Diviser les données en ensemble d'entraînement et de test\n",
    "print(\"Division des données en ensemble d'entraînement et de test...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(\"Division effectuée avec succès.\\n\")\n",
    "\n",
    "# 4. Entraîner le modèle de régression logistique\n",
    "print(\"Entraînement du modèle de régression logistique...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 5. Évaluation du modèle\n",
    "print(\"Évaluation du modèle...\")\n",
    "train_score = pipeline.score(X_train, y_train)\n",
    "test_score = pipeline.score(X_test, y_test)\n",
    "\n",
    "print(f\"Score d'entraînement du modèle de régression logistique: {train_score}\")\n",
    "print(f\"Score de test du modèle de régression logistique: {test_score}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaaee34-537b-48e1-a58f-39d31d4a0dcd",
   "metadata": {},
   "source": [
    "# Arbre de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b84ed9f5-c62f-4f07-81fb-f221b34671ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données...\n",
      "Données chargées avec succès.\n",
      "\n",
      "Préparation des données...\n",
      "Distribution des classes dans la cible :\n",
      "TARGET\n",
      "0    0.919271\n",
      "1    0.080729\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "\n",
      "Division des données en ensemble d'entraînement et de test...\n",
      "Division effectuée avec succès.\n",
      "\n",
      "Entraînement du DecisionTreeClassifier...\n",
      "Évaluation du modèle...\n",
      "Score d'entraînement du DecisionTreeClassifier: 1.0\n",
      "Score de test du DecisionTreeClassifier: 0.8524183233247339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1. Charger les données\n",
    "print(\"Chargement des données...\")\n",
    "df = pd.read_csv('data/application_train.csv')\n",
    "print(\"Données chargées avec succès.\\n\")\n",
    "\n",
    "# 2. Préparer les données (utiliser toutes les colonnes comme caractéristiques)\n",
    "print(\"Préparation des données...\")\n",
    "X = df.drop(columns=['TARGET'])\n",
    "y = df['TARGET']\n",
    "\n",
    "# Remplacer les valeurs manquantes pour les colonnes numériques\n",
    "X = X.fillna(X.median(numeric_only=True))  # Utiliser median pour les colonnes numériques\n",
    "\n",
    "# Identifier les colonnes numériques et catégorielles\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Prétraitement des caractéristiques\n",
    "numeric_transformer = SimpleImputer(strategy='median')\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Créer un pipeline avec DecisionTreeClassifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "# 3. Vérifier la distribution des classes\n",
    "print(\"Distribution des classes dans la cible :\")\n",
    "print(y.value_counts(normalize=True))\n",
    "print(\"\\n\")\n",
    "\n",
    "# 4. Diviser les données en ensemble d'entraînement et de test\n",
    "print(\"Division des données en ensemble d'entraînement et de test...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(\"Division effectuée avec succès.\\n\")\n",
    "\n",
    "# 5. Entraîner et évaluer le DecisionTreeClassifier\n",
    "print(\"Entraînement du DecisionTreeClassifier...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 6. Évaluation du modèle\n",
    "print(\"Évaluation du modèle...\")\n",
    "train_score = pipeline.score(X_train, y_train)\n",
    "test_score = pipeline.score(X_test, y_test)\n",
    "print(f\"Score d'entraînement du DecisionTreeClassifier: {train_score}\")\n",
    "print(f\"Score de test du DecisionTreeClassifier: {test_score}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba041e5-589e-47e2-b0ef-1ab70bd3e15a",
   "metadata": {},
   "source": [
    "# random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "96529c7b-32f1-4220-8a95-c4da7e7140c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données...\n",
      "Données chargées avec succès.\n",
      "\n",
      "Préparation des données...\n",
      "Division des données en ensemble d'entraînement et de test...\n",
      "Division effectuée avec succès.\n",
      "\n",
      "Entraînement du modèle Random Forest...\n",
      "Évaluation du modèle...\n",
      "Score d'entraînement du modèle Random Forest: 0.999944252684001\n",
      "Score de test du modèle Random Forest: 0.9181173716044833\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1. Charger les données\n",
    "print(\"Chargement des données...\")\n",
    "df = pd.read_csv('data/application_train.csv')\n",
    "print(\"Données chargées avec succès.\\n\")\n",
    "\n",
    "# 2. Préparer les données (utiliser toutes les colonnes comme caractéristiques)\n",
    "print(\"Préparation des données...\")\n",
    "X = df.drop(columns=['TARGET'])\n",
    "y = df['TARGET']\n",
    "\n",
    "# Remplacer les valeurs manquantes pour les colonnes numériques\n",
    "X = X.fillna(X.median(numeric_only=True))  # Utiliser median pour les colonnes numériques\n",
    "\n",
    "# Identifier les colonnes numériques et catégorielles\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Prétraitement des caractéristiques\n",
    "numeric_transformer = SimpleImputer(strategy='median')\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Créer un pipeline avec RandomForestClassifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# 3. Diviser les données en ensemble d'entraînement et de test\n",
    "print(\"Division des données en ensemble d'entraînement et de test...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(\"Division effectuée avec succès.\\n\")\n",
    "\n",
    "# 4. Entraîner le modèle Random Forest\n",
    "print(\"Entraînement du modèle Random Forest...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 5. Évaluation du modèle\n",
    "print(\"Évaluation du modèle...\")\n",
    "train_score = pipeline.score(X_train, y_train)\n",
    "test_score = pipeline.score(X_test, y_test)\n",
    "\n",
    "print(f\"Score d'entraînement du modèle Random Forest: {train_score}\")\n",
    "print(f\"Score de test du modèle Random Forest: {test_score}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
